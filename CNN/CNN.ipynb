{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04512a4f",
   "metadata": {},
   "source": [
    "We will be implementing a CNN from scratch heere using just Numpy. Here, I will keep the entire evolution of code until we get a final, polished CNN architecture. This way, we can understand the problems and implementations in a chronological way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d020df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec192cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the fundamentals of CNN:\n",
    "\n",
    "#Take W size Input Image.\n",
    "#Use a filter of size K.\n",
    "#Return output of size W-k+1 (No Padding, No Stride).\n",
    "#We will use and understand Padding & Stride as we progress into bottlenecks and more complex problems. \n",
    "#The main task here is to develop algorithm to convolute the filter through the image.\n",
    "\n",
    "class con2d:\n",
    "    def __init__(self, w, k):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.filter = np.random.rand(k,k)\n",
    "        self.bias = random.uniform(-1,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sum = 0\n",
    "        Y = np.zeros((self.W + 1 - self.K, self.W + 1 - self.K))\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        sum += patch[a,b] * self.filter[a,b]\n",
    "                #sum += self.bias\n",
    "                #sum = np.tanh(sum)\n",
    "                Y[i,j] = sum\n",
    "                sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c469f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.,  0.,  2.],\n",
       "       [-3., -2.,  2.],\n",
       "       [-3., -1.,  2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = np.array([\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "myCNN = con2d(5,3)\n",
    "myCNN.filter = kernel\n",
    "myCNN.forward(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e7c91",
   "metadata": {},
   "source": [
    "This was an extremely inefficient implementation but we did get correct outcome. For now lets focus on the fact that CNNs work on rgb data which has 3 channels. But our code assumes an image as a flat 2D surface. We have to add depth/channel to our input matrix and thus our kernel. But importantly, our output matrix/activation map must remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class con2d:\n",
    "    def __init__(self, w, k, c):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.C = c #Channel\n",
    "        self.filter = np.random.rand(k,k,c)\n",
    "        self.bias = random.uniform(-1,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sum = 0\n",
    "        Y = np.zeros((self.W + 1 - self.K, self.W + 1 - self.K))\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K, :]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        for c in range(self.C):\n",
    "                            sum += patch[a,b,c] * self.filter[a,b,c]\n",
    "                #sum += self.bias\n",
    "                #sum = np.tanh(sum)\n",
    "                Y[i,j] = sum\n",
    "                sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c68f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9., -9.],\n",
       "       [-9., -9.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vol = np.zeros((4, 4, 2))\n",
    "input_vol[:, :, 0] = 1\n",
    "input_vol[:, :, 1] = 2\n",
    "\n",
    "kernel = np.zeros((3, 3, 2))\n",
    "kernel[:, :, 0] = 1\n",
    "kernel[:, :, 1] = -1\n",
    "\n",
    "myCNN = con2d(4,3,2)\n",
    "myCNN.filter = kernel\n",
    "myCNN.forward(input_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e517e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make this complete, lets uncomment bias application and let's try to have more than one filters.\n",
    "class con2d:\n",
    "    def __init__(self, w, k, c, n):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.C = c #Channels\n",
    "        self.Cn = n #Number of filters\n",
    "        self.filters = [np.random.rand(k,k,c) for _ in range(n)]\n",
    "        self.bias = [random.uniform(-1,1) for _ in range(n)]\n",
    "\n",
    "    def forward(self, X):\n",
    "        sums = np.zeros(self.Cn)\n",
    "        Y = [np.zeros((self.W + 1 - self.K, self.W + 1 - self.K)) for _ in range(self.Cn)]\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K, :]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        for c in range(self.C):\n",
    "                            for index, filter in enumerate(self.filters):\n",
    "                                sums[index] += patch[a,b,c] * filter[a,b,c]\n",
    "                for idx, sum in enumerate(sums):\n",
    "                    sum += self.bias[idx]\n",
    "                    #sum = np.tanh(sum)\n",
    "                    Y[idx][i,j] = sum\n",
    "                    sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaaee71",
   "metadata": {},
   "source": [
    "But these nested loops are extremely inefficient. We have to adress this. Modern libraries like pytorch and tensorflow use a standard practice called \"im2col\" where the entire image is stretched into a single vector arranged by the filter size. One way is to then also dilate our filter adding zeros in between such that a single matrix multiplication will simulate the filter being slid over the image. \n",
    "\n",
    "This however, would be inefficient. Why? We aren't using multiple nested loops which significantly improve performance. But, we are doing unecessarily large matrix multiplication involving 0 elements.\n",
    "\n",
    "\n",
    "Best and SoTA practice is to flatten the image locally. I.e. we flatten only the receptive field of the kernel eg. 3x3x3, and then matmul it with our flattened kernel(3x3x3). This results in matmul between a 1x27 image and 27x1 kernel, resulting in a single scalar value. This scalar corresponds to a single pixel of the activation map after being added to the scalar bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a6085",
   "metadata": {},
   "source": [
    "Let's take an example. Start from inputs of dimension 16x3x32x32 where 16 is the batch size, 3 is the number of channels and 32x32 is the image size. So we have 16 rgb images of 32x32 resolution as input each batch. Consider a kernel size of 128x3x2x2 where 128 is the number of kernels, 3 represents rgb and 3x3 is the kernel size. \n",
    "\n",
    "How does im2col work in this case? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32d88c",
   "metadata": {},
   "source": [
    "Firstly, calculate the receptive field size or the output field size.\n",
    "\n",
    "O = ((I - K + 2P)/S) + 1\n",
    "\n",
    "This is the standard formula where:\n",
    "- I : Input image size (eg. 32x32)\n",
    "- K : Kernel size (eg. 3x3)\n",
    "- P : Zero Padding size (eg. 0 or 1 if we want O to be 32 = I)\n",
    "- S : Stride (eg. 1)\n",
    "- O : Output Activation size\n",
    "\n",
    "Here, \n",
    "\n",
    "O = ((32-3+0)/1) + 1 = 30\n",
    "\n",
    "So we get activation map of 30x30 per kernel.\n",
    "\n",
    "If we want the activation map to be same size of that of input, we have to introduce padding: Specifically same padding. \n",
    "\n",
    "In our example, same padding requires padding = 1\n",
    "\n",
    "Therefore we get, O = ((32-3+2)/1) + 1 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab4571",
   "metadata": {},
   "source": [
    "For now, let us assume the initial case with no Padding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60637dec",
   "metadata": {},
   "source": [
    "## Im2col Transformation Step-by-Step\n",
    "\n",
    "### Given:\n",
    "- Input: (16, 3, 32, 32) - 16 batches, 3 channels, 32×32 images\n",
    "- Kernels: (128, 3, 3, 3) - 128 output channels/kernels/activation maps, 3 input channels, 3×3 spatial\n",
    "- Output size: O = ((32 - 3 + 0) / 1) + 1 = **30×30**\n",
    "\n",
    "### Step 1: Extract All Receptive Fields\n",
    "\n",
    "For each image in the batch:\n",
    "- Each receptive field: 3×3×3 = **27 elements**\n",
    "- Number of positions: 30×30 = **900 positions**\n",
    "- Total number of flattened matrices that represent all positions: **(900, 27)** (But this flatenning requires special handling so that we differentiate from 27 contigious memory of the image, and 27 neighbouring pixels that constitute a receptive field.)\n",
    "\n",
    "For the entire batch (16 images):\n",
    "- We stack all of them vertically (16 × 900, 27) = **(14,400, 27)**\n",
    "\n",
    "### Step 2: Flatten All 128 Kernels\n",
    "\n",
    "- Each kernel: 3×3×3 = 27 elements\n",
    "- Kernels shape: **(27, 128)**\n",
    "\n",
    "Why? 27 weights for each 128 kernels. \n",
    "\n",
    "### Step 3: Giant MatMul\n",
    "\n",
    "(14,400, 27) @ (27, 128) = **(14,400, 128)**\n",
    "\n",
    "### Step 4: Reshape and Add Bias\n",
    "\n",
    "Reshape (14,400, 128) → (16, 128, 30, 30)\n",
    "Add bias (128,) → broadcasts to (16, 128, 30, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f627a",
   "metadata": {},
   "source": [
    "## So lets draw some conclusions first!\n",
    "\n",
    "1. We need special type of matrix flatenning such that all pixels of local receptive fields(3x3x3 = 27) are in one dimension(x, 27) and all such local receptive fields(30x30 = 900) are in another, batch dimension(900, x) which represents the number of such possible receptive fields. This corresponds to number of pixels in activation map. Finally we need to consider all the receptive fields of all images in the batch. This doesnot create new dimension (not, eg. 16x900x27), but we stack all the receptive fields of all the images vertically. (i.e 900x16 = 14,400). Therefore we get final flatenned 2D matrix of shape = 14400, 27.\n",
    "\n",
    "    ## Therefore:\n",
    "    Local receptive field pixels must be arranged non contigiously relative to the image.\n",
    "\n",
    "    eg.\n",
    "\n",
    "    11  12  13\n",
    "\n",
    "    21  22  23\n",
    "\n",
    "    31  32  33\n",
    "\n",
    "    should not be flattened as: \n",
    "\n",
    "    [11, 12, 13, 14],\n",
    "        \n",
    "    [13, 21, 22, 23], \n",
    "\n",
    "\n",
    "    [22, 23, 31, 32], \n",
    "\n",
    "    [31, 32, 33, 11] \n",
    "\n",
    "    Shape(4x4)\n",
    "\n",
    "    or,\n",
    "\n",
    "    [1,2,3,4,5,6,7,8,9] : Shape (9)\n",
    "\n",
    "    But as:\n",
    "    \n",
    "    [11, 12, 21, 22],\n",
    "\n",
    "    [12, 13, 22, 23],\n",
    "\n",
    "    [21, 22, 23, 31],\n",
    "\n",
    "    [22, 23, 32, 33]\n",
    "\n",
    "    Shape(4x4)\n",
    "\n",
    "\n",
    "2. To define our convolution layer, we need to know some parameters:\n",
    "- Depth/No. of Channels of Kernel which corresponds to input channels(in_channels)\n",
    "- Depth/No. of Channels of Activation/Output which corresponds to number of kernels (out_channels)\n",
    "- Kernel size (kernel_size eg.(2) -> 2x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor:\n",
    "    def __init__(self, fromArray=np.zeros((2,2)), _children = (), _operation = ''):\n",
    "        fromArray = fromArray if isinstance(fromArray, np.ndarray) else np.array(fromArray)\n",
    "        #assert len(fromArray.shape) == 2, \"Only 2D Tensors or Scalar to 2D Supported!\"\n",
    "        self.matrix = fromArray\n",
    "        #self.rows = fromArray.shape[0]\n",
    "        #self.columns = fromArray.shape[1]\n",
    "        self.shape = fromArray.shape\n",
    "        self._prev = set(_children)\n",
    "        self._operation = _operation\n",
    "        self._backward = lambda : None\n",
    "        self.grad = None\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor Values = {self.matrix}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def zeros(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = np.zeros(shape, dtype=dtype)\n",
    "        t.shape = shape\n",
    "        #t.rows = rows\n",
    "        #t.columns = columns\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.random.randn(*shape) * 0.1).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def const(cls, shape, constant=1, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.full(shape, constant)).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        #t.rows = rows\n",
    "        #t.columns = columns\n",
    "        return t\n",
    "    \n",
    "    #Operations\n",
    "    def __add__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix + other.matrix\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            out2 = other.return_unbroadcasted(out)\n",
    "            self.grad += out1 #Derivation in the notes. \n",
    "            other.grad += out2\n",
    "        out = tensor(out_matrix, (self, other), '+')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self + (-1 * other)\n",
    "    \n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return other + (-1 * other)\n",
    "    \n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix * other.matrix\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(out.grad) if other.grad is None else other.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            out2 = other.return_unbroadcasted(out)\n",
    "            self.grad += out1* other.matrix #Derivation in the notes. \n",
    "            other.grad += out2 * self.matrix\n",
    "\n",
    "        out = tensor(out_matrix, (self, other), '*')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    '''\n",
    "    batch multiplication might cause shape broadcasts.\n",
    "    eg. (3,2,2) @ (1,2,3) = (3,2,3)\n",
    "    this is similar to our element wise operations\n",
    "    thus we should be handling this the same way we did for elementwise operations\n",
    "    But, for now, we would be working in a controlled way (Even for CNNS)\n",
    "    and wouldn't need this handling.\n",
    "    '''\n",
    "    def __matmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        assert other.shape()[0] == self.shape()[-1], \"Dimension Unsupported for @\"\n",
    "        out_matrix = self.matrix @ other.matrix\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            self.grad += out.grad @ (other.matrix).swapaxes(-2,-1)#Derivation in the notes.\n",
    "            other.grad += (self.matrix).swapaxes(-2,-1) @ out.grad \n",
    "        out = tensor(out_matrix, (self, other), '@')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "\n",
    "    #I and thus we should learn at this point that to make our class compatible for ND tensors,\n",
    "    #We need the matrix multiplication and Transpose backward to change\n",
    "    #For higher dimensions, matmul = batch matmul where multiplication is done \n",
    "    #along each and every batches of 2D matrix. \n",
    "    #eg. If we have (2,3,3) shape tensor, it implies there are two batches of (3,3) matrices\n",
    "    #similarly, (2,3,3,2) shape = 2x3 batches of 3x2 matrices.\n",
    "    #matrix multiplication, (2,3,3) @ (2,3,2) = (2,3,2)\n",
    "    def swap_axes(self, axis1, axis2):\n",
    "        out_matrix = self.matrix.swapaxes(axis1, axis2)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad.swapaxes(axis1,axis2)) if self.grad is None else self.grad\n",
    "            self.grad += (out.grad).swapaxes(axis1,axis2) #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def transpose(self):\n",
    "        out_matrix = self.matrix.transpose()\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad.transpose()) if self.grad is None else self.grad\n",
    "            self.grad += (out.grad).transpose() #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __rmatmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        return other @ self\n",
    "    \n",
    "    def __pow__(self, N):\n",
    "        assert isinstance(N, int | float), \"Can only power up by scalars!\"\n",
    "        out_matrix = self.matrix ** N\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            self.grad += N * (self.matrix ** (N-1)) * out1\n",
    "        \n",
    "        out = tensor(out_matrix, _children=(self, ), _operation=\"**\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self * (other**-1)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return other * (self**-1)\n",
    "    \n",
    "    def sum(self):\n",
    "        out_matrix = np.array(([[self.matrix.sum()]]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * out.grad\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='sum()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def mean(self):\n",
    "        N = np.prod(self.shape)\n",
    "        out_matrix = np.array(([[self.matrix.sum()/(N)]]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * out.grad / N\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='mean()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def ReLU(self):\n",
    "        out_matrix = np.maximum(0,self.matrix)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (self.matrix > 0).astype(self.matrix.dtype) * out.grad\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"ReLU\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def reshape(self, shape):\n",
    "        assert isinstance(shape, tuple), f\"Can only reshape using shape tuples e.g. (3,3). Provided is {shape}\"\n",
    "        out_matrix = self.matrix.reshape(shape)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"reshape()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def flatten(self):\n",
    "        out_matrix = self.matrix.reshape(-1,np.prod(self.shape[1:]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"flatten()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    #Helper Functions\n",
    "    #def shape(self):\n",
    "     #   return (self.rows, self.columns)\n",
    "\n",
    "    def return_unbroadcasted(self, out):  \n",
    "        added_axis = []\n",
    "        stretched_axis = []\n",
    "        for index, (first_no, second_no) in enumerate(itertools.zip_longest(reversed(self.shape), reversed(out.shape))):\n",
    "            if first_no is None:\n",
    "                added_axis.append(index)\n",
    "            elif (first_no == 1) and (second_no > 1):\n",
    "                stretched_axis.append(index)\n",
    "        grad = out.grad\n",
    "        ndim = len(out.shape)\n",
    "        if stretched_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in stretched_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=True)\n",
    "        if added_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in added_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=False)\n",
    "        return grad\n",
    "\n",
    "    def checkOther(self, other):\n",
    "        if isinstance(other, int | float):\n",
    "            other = tensor.const(self.shape, other)\n",
    "        elif not isinstance(other, tensor):\n",
    "            other = tensor(other)\n",
    "        #assert other.shape == self.shape, \"Operand Tensor sizes dont match\"\n",
    "\n",
    "        return other\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.grad = None\n",
    "        \n",
    "    def backward(self):\n",
    "        self.grad = np.ones_like(self.matrix, dtype=float)\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for current in reversed(topo):\n",
    "\n",
    "            current._backward()\n",
    "\n",
    "    __array_ufunc__ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f24cb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size, stride):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            grad_6D = np.reshape(out.grad, shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w,))\n",
    "\n",
    "            #For each element in this 6D tensor, having 6D index, we have to calculate the coresponding 4D index.\n",
    "            #The formula has been conceptually derived in the notes.\n",
    "            #Here, we first generate all the indices of the 6D tensor and store each index dimension in separate list\n",
    "            #Then using the derived formula, we batch convert the 6D indices to 4D indices.\n",
    "\n",
    "            batch = np.arange(batch_size).reshape(batch_size,1,1,1,1,1)\n",
    "            field_h = np.arange(act_h).reshape(1,act_h,1,1,1,1)\n",
    "            field_w = np.arange(act_w).reshape(1,1,act_w,1,1,1)\n",
    "            channel = np.arange(channels).reshape(1,1,1,channels,1,1)\n",
    "            k_h = np.arange(kernel_h).reshape(1,1,1,1,kernel_h,1)\n",
    "            k_w = np.arange(kernel_w).reshape(1,1,1,1,1,kernel_w)\n",
    "\n",
    "            x = stride * field_h + k_h\n",
    "            y = stride * field_w + k_w\n",
    "\n",
    "            np.add.at(X.grad, (batch, channel, x, y), grad_6D)\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51acf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  (16, 3, 5, 5)\n",
      "Output Shape:  (64, 27)\n"
     ]
    }
   ],
   "source": [
    "batch = tensor(np.random.randn(16, 3, 5, 5).astype(float))\n",
    "\n",
    "print(\"Input Shape: \", batch.shape)\n",
    "\n",
    "im2col = Conv2d.im2col(batch, 3, 2)\n",
    "\n",
    "print(\"Output Shape: \", im2col.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a5042",
   "metadata": {},
   "source": [
    "This was a valid approach. Elegant and shows the direct use of formula. But, we have an even more efficient approach. It involves slicing. In this method, instead of creating large index array which requires both time and memory, we can call 2 simple for loops to loop over the kernel sizes and slice the out.grad array for each position of the kernel index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "664a1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size, stride):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            \n",
    "            grad_6D = out.grad.reshape(batch_size, act_h, act_w, channels, kernel_h, kernel_w)\n",
    "\n",
    "            for i in range(kernel_h):\n",
    "                for j in range(kernel_w):\n",
    "                    # 1. Extract the gradient slice for this kernel position\n",
    "                    grad_slice = grad_6D[:, :, :, :, i, j]\n",
    "                    \n",
    "                    grad_slice_transposed = grad_slice.transpose(0, 3, 1, 2)\n",
    "                    \n",
    "                    X.grad[:, :, \n",
    "                        i : i + act_h * stride : stride, \n",
    "                        j : j + act_w * stride : stride\n",
    "                    ] += grad_slice_transposed\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "        \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595effa9",
   "metadata": {},
   "source": [
    "## Testing im2col Forward and Backward\n",
    "\n",
    "Let's verify that both the forward and backward passes work correctly with a concrete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a7385c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: Forward Pass\n",
      "======================================================================\n",
      "Input shape: (2, 1, 5, 5)\n",
      "Input (batch 0):\n",
      "[[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14.]\n",
      " [15. 16. 17. 18. 19.]\n",
      " [20. 21. 22. 23. 24.]]\n",
      "\n",
      "Output shape: (8, 4)\n",
      "Expected: (2 * 2 * 2, 1 * 2 * 2) = (8, 4)\n",
      "\n",
      "Output matrix (first few rows):\n",
      "[[ 0.  1.  5.  6.]\n",
      " [ 2.  3.  7.  8.]\n",
      " [10. 11. 15. 16.]\n",
      " [12. 13. 17. 18.]]\n",
      "\n",
      "Manual verification - First patch (batch 0, position [0,0]):\n",
      "Should contain pixels at positions (0,0), (0,1), (1,0), (1,1)\n",
      "Expected: [0.0, 1.0, 5.0, 6.0]\n",
      "Got:      [0. 1. 5. 6.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Forward pass with simple input\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 1: Forward Pass\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a simple input: (2, 1, 5, 5) - 2 batches, 1 channel, 5x5 image\n",
    "X_test = tensor(np.arange(50).reshape(2, 1, 5, 5).astype(float))\n",
    "print(f\"Input shape: {X_test.shape}\")\n",
    "print(f\"Input (batch 0):\\n{X_test.matrix[0, 0]}\")\n",
    "print()\n",
    "\n",
    "# Apply im2col with kernel_size=2, stride=2\n",
    "out_test = Conv2d.im2col(X_test, kernel_size=2, stride=2)\n",
    "print(f\"Output shape: {out_test.shape}\")\n",
    "print(f\"Expected: (2 * 2 * 2, 1 * 2 * 2) = (8, 4)\")\n",
    "print()\n",
    "\n",
    "# Check the output values\n",
    "print(f\"Output matrix (first few rows):\")\n",
    "print(out_test.matrix[:4])\n",
    "print()\n",
    "\n",
    "# Manually verify the first patch (top-left of batch 0)\n",
    "print(\"Manual verification - First patch (batch 0, position [0,0]):\")\n",
    "print(\"Should contain pixels at positions (0,0), (0,1), (1,0), (1,1)\")\n",
    "first_batch = X_test.matrix[0, 0]\n",
    "print(f\"Expected: [{first_batch[0,0]}, {first_batch[0,1]}, {first_batch[1,0]}, {first_batch[1,1]}]\")\n",
    "print(f\"Got:      {out_test.matrix[0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38ae0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 2: Backward Pass\n",
      "======================================================================\n",
      "Input shape: (1, 1, 4, 4)\n",
      "Input values (all ones):\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Output shape: (9, 4)\n",
      "Expected: (1 * 3 * 3, 1 * 2 * 2) = (9, 4)\n",
      "\n",
      "Output gradient (all ones): shape (9, 4)\n",
      "\n",
      "Input gradient shape: (1, 1, 4, 4)\n",
      "Input gradient:\n",
      "[[1. 2. 2. 1.]\n",
      " [2. 4. 4. 2.]\n",
      " [2. 4. 4. 2.]\n",
      " [1. 2. 2. 1.]]\n",
      "\n",
      "Expected gradient pattern:\n",
      "  Corner pixels (e.g., [0,0]): contribute to 1 output position → grad = 1\n",
      "  Edge pixels: contribute to 2 output positions → grad = 2\n",
      "  Interior pixels: contribute to 4 output positions → grad = 4\n",
      "\n",
      "Gradient at corner [0,0]: 1.0 (expected: 1)\n",
      "Gradient at edge [0,1]: 2.0 (expected: 2)\n",
      "Gradient at interior [1,1]: 4.0 (expected: 4)\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Backward pass - verify gradients flow correctly\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 2: Backward Pass\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a simple input\n",
    "X_back = tensor(np.ones((1, 1, 4, 4), dtype=float))\n",
    "print(f\"Input shape: {X_back.shape}\")\n",
    "print(f\"Input values (all ones):\\n{X_back.matrix[0, 0]}\")\n",
    "print()\n",
    "\n",
    "# Forward: kernel_size=2, stride=1 → output is 3x3\n",
    "out_back = Conv2d.im2col(X_back, kernel_size=2, stride=1)\n",
    "print(f\"Output shape: {out_back.shape}\")\n",
    "print(f\"Expected: (1 * 3 * 3, 1 * 2 * 2) = (9, 4)\")\n",
    "print()\n",
    "\n",
    "# Create gradient: all ones for simplicity\n",
    "out_back.grad = np.ones_like(out_back.matrix)\n",
    "print(f\"Output gradient (all ones): shape {out_back.grad.shape}\")\n",
    "print()\n",
    "\n",
    "# Call backward\n",
    "out_back._backward()\n",
    "\n",
    "print(f\"Input gradient shape: {X_back.grad.shape}\")\n",
    "print(f\"Input gradient:\\n{X_back.grad[0, 0]}\")\n",
    "print()\n",
    "\n",
    "# Explanation: With kernel 2x2 and stride 1, each position in the input\n",
    "# contributes to multiple output positions (overlapping receptive fields)\n",
    "print(\"Expected gradient pattern:\")\n",
    "print(\"  Corner pixels (e.g., [0,0]): contribute to 1 output position → grad = 1\")\n",
    "print(\"  Edge pixels: contribute to 2 output positions → grad = 2\")  \n",
    "print(\"  Interior pixels: contribute to 4 output positions → grad = 4\")\n",
    "print()\n",
    "\n",
    "# Verify corner [0,0]\n",
    "print(f\"Gradient at corner [0,0]: {X_back.grad[0, 0, 0, 0]} (expected: 1)\")\n",
    "# Verify edge [0,1] or [1,0]  \n",
    "print(f\"Gradient at edge [0,1]: {X_back.grad[0, 0, 0, 1]} (expected: 2)\")\n",
    "# Verify interior [1,1]\n",
    "print(f\"Gradient at interior [1,1]: {X_back.grad[0, 0, 1, 1]} (expected: 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1c8209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 3: Stride > 1 Case\n",
      "======================================================================\n",
      "Input shape: (1, 1, 5, 5)\n",
      "Input:\n",
      "[[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14.]\n",
      " [15. 16. 17. 18. 19.]\n",
      " [20. 21. 22. 23. 24.]]\n",
      "\n",
      "Output shape: (4, 4)\n",
      "Expected: (1 * 2 * 2, 1 * 2 * 2) = (4, 4)\n",
      "\n",
      "Output patches:\n",
      "[[ 0.  1.  5.  6.]\n",
      " [ 2.  3.  7.  8.]\n",
      " [10. 11. 15. 16.]\n",
      " [12. 13. 17. 18.]]\n",
      "\n",
      "Verification:\n",
      "Patch at [0,0]: positions (0,0), (0,1), (1,0), (1,1) → [0. 1. 5. 6.]\n",
      "Got: [0. 1. 5. 6.]\n",
      "\n",
      "Patch at [0,2]: positions (0,2), (0,3), (1,2), (1,3) → [2. 3. 7. 8.]\n",
      "Got: [2. 3. 7. 8.]\n",
      "\n",
      "Input gradient with stride=2:\n",
      "[[1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "Expected: Each receptive field position gets gradient 1\n",
      "With stride=2, no overlaps → all touched positions should have grad=1\n",
      "Untouched positions (e.g., last row/col) should have grad=0\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Verify slicing approach with stride > 1\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 3: Stride > 1 Case\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Input: (1, 1, 5, 5)\n",
    "X_stride = tensor(np.arange(25).reshape(1, 1, 5, 5).astype(float))\n",
    "print(f\"Input shape: {X_stride.shape}\")\n",
    "print(f\"Input:\\n{X_stride.matrix[0, 0]}\")\n",
    "print()\n",
    "\n",
    "# Forward: kernel_size=2, stride=2 → output is 2x2\n",
    "out_stride = Conv2d.im2col(X_stride, kernel_size=2, stride=2)\n",
    "print(f\"Output shape: {out_stride.shape}\")\n",
    "print(f\"Expected: (1 * 2 * 2, 1 * 2 * 2) = (4, 4)\")\n",
    "print()\n",
    "print(f\"Output patches:\")\n",
    "print(out_stride.matrix)\n",
    "print()\n",
    "\n",
    "# Each row should correspond to one 2x2 patch\n",
    "print(\"Verification:\")\n",
    "print(f\"Patch at [0,0]: positions (0,0), (0,1), (1,0), (1,1) → {X_stride.matrix[0,0,0:2,0:2].flatten()}\")\n",
    "print(f\"Got: {out_stride.matrix[0]}\")\n",
    "print()\n",
    "print(f\"Patch at [0,2]: positions (0,2), (0,3), (1,2), (1,3) → {X_stride.matrix[0,0,0:2,2:4].flatten()}\")\n",
    "print(f\"Got: {out_stride.matrix[1]}\")\n",
    "print()\n",
    "\n",
    "# Test backward with stride=2\n",
    "out_stride.grad = np.ones_like(out_stride.matrix)\n",
    "out_stride._backward()\n",
    "\n",
    "print(f\"Input gradient with stride=2:\")\n",
    "print(X_stride.grad[0, 0])\n",
    "print()\n",
    "print(\"Expected: Each receptive field position gets gradient 1\")\n",
    "print(\"With stride=2, no overlaps → all touched positions should have grad=1\")\n",
    "print(\"Untouched positions (e.g., last row/col) should have grad=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acec344",
   "metadata": {},
   "source": [
    "## Summary: im2col Forward & Backward Work Correctly! ✓\n",
    "\n",
    "**Forward Pass:**\n",
    "- Correctly extracts all receptive fields using `as_strided`\n",
    "- Reshapes to 2D for efficient matrix multiplication\n",
    "- Example: (1, 1, 5, 5) with kernel=2, stride=2 → (4, 4) ✓\n",
    "\n",
    "**Backward Pass (Slicing Approach):**\n",
    "- Correctly accumulates gradients back to input\n",
    "- Handles overlapping receptive fields (stride=1): interior pixels get 4× gradient ✓\n",
    "- Handles non-overlapping receptive fields (stride=2): touched pixels get 1×, untouched get 0× ✓\n",
    "- Uses efficient slicing: `X.grad[:, :, i:i+act_h*stride:stride, j:j+act_w*stride:stride] += grad_slice_transposed`\n",
    "\n",
    "**Key Insight:**\n",
    "The slicing approach works because each `(i, j)` kernel position maps to a specific strided slice of the input. The slice shape `(batch, channels, act_h, act_w)` matches `grad_slice_transposed`, so the `+=` operation is valid. Across all kernel positions, these slices cover the entire input (with overlaps when stride < kernel_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332937a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
