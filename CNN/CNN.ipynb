{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04512a4f",
   "metadata": {},
   "source": [
    "We will be implementing a CNN from scratch heere using just Numpy. Here, I will keep the entire evolution of code until we get a final, polished CNN architecture. This way, we can understand the problems and implementations in a chronological way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d020df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8ec192cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the fundamentals of CNN:\n",
    "\n",
    "#Take W size Input Image.\n",
    "#Use a filter of size K.\n",
    "#Return output of size W-k+1 (No Padding, No Stride).\n",
    "#We will use and understand Padding & Stride as we progress into bottlenecks and more complex problems. \n",
    "#The main task here is to develop algorithm to convolute the filter through the image.\n",
    "\n",
    "class con2d:\n",
    "    def __init__(self, w, k):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.filter = np.random.rand(k,k)\n",
    "        self.bias = random.uniform(-1,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sum = 0\n",
    "        Y = np.zeros((self.W + 1 - self.K, self.W + 1 - self.K))\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        sum += patch[a,b] * self.filter[a,b]\n",
    "                #sum += self.bias\n",
    "                #sum = np.tanh(sum)\n",
    "                Y[i,j] = sum\n",
    "                sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b6c469f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.,  0.,  2.],\n",
       "       [-3., -2.,  2.],\n",
       "       [-3., -1.,  2.]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = np.array([\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "myCNN = con2d(5,3)\n",
    "myCNN.filter = kernel\n",
    "myCNN.forward(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e7c91",
   "metadata": {},
   "source": [
    "This was an extremely inefficient implementation but we did get correct outcome. For now lets focus on the fact that CNNs work on rgb data which has 3 channels. But our code assumes an image as a flat 2D surface. We have to add depth/channel to our input matrix and thus our kernel. But importantly, our output matrix/activation map must remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "bd9d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class con2d:\n",
    "    def __init__(self, w, k, c):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.C = c #Channel\n",
    "        self.filter = np.random.rand(k,k,c)\n",
    "        self.bias = random.uniform(-1,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sum = 0\n",
    "        Y = np.zeros((self.W + 1 - self.K, self.W + 1 - self.K))\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K, :]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        for c in range(self.C):\n",
    "                            sum += patch[a,b,c] * self.filter[a,b,c]\n",
    "                #sum += self.bias\n",
    "                #sum = np.tanh(sum)\n",
    "                Y[i,j] = sum\n",
    "                sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "03c68f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9., -9.],\n",
       "       [-9., -9.]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vol = np.zeros((4, 4, 2))\n",
    "input_vol[:, :, 0] = 1\n",
    "input_vol[:, :, 1] = 2\n",
    "\n",
    "kernel = np.zeros((3, 3, 2))\n",
    "kernel[:, :, 0] = 1\n",
    "kernel[:, :, 1] = -1\n",
    "\n",
    "myCNN = con2d(4,3,2)\n",
    "myCNN.filter = kernel\n",
    "myCNN.forward(input_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9e517e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make this complete, lets uncomment bias application and let's try to have more than one filters.\n",
    "class con2d:\n",
    "    def __init__(self, w, k, c, n):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.C = c #Channels\n",
    "        self.Cn = n #Number of filters\n",
    "        self.filters = [np.random.rand(k,k,c) for _ in range(n)]\n",
    "        self.bias = [random.uniform(-1,1) for _ in range(n)]\n",
    "\n",
    "    def forward(self, X):\n",
    "        sums = np.zeros(self.Cn)\n",
    "        Y = [np.zeros((self.W + 1 - self.K, self.W + 1 - self.K)) for _ in range(self.Cn)]\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K, :]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        for c in range(self.C):\n",
    "                            for index, filter in enumerate(self.filters):\n",
    "                                sums[index] += patch[a,b,c] * filter[a,b,c]\n",
    "                for idx, sum in enumerate(sums):\n",
    "                    sum += self.bias[idx]\n",
    "                    #sum = np.tanh(sum)\n",
    "                    Y[idx][i,j] = sum\n",
    "                    sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaaee71",
   "metadata": {},
   "source": [
    "But these nested loops are extremely inefficient. We have to adress this. Modern libraries like pytorch and tensorflow use a standard practice called \"im2col\" where the entire image is stretched into a single vector arranged by the filter size. One way is to then also dilate our filter adding zeros in between such that a single matrix multiplication will simulate the filter being slid over the image. \n",
    "\n",
    "This however, would be inefficient. Why? We aren't using multiple nested loops which significantly improve performance. But, we are doing unecessarily large matrix multiplication involving 0 elements.\n",
    "\n",
    "\n",
    "Best and SoTA practice is to flatten the image locally. I.e. we flatten only the receptive field of the kernel eg. 3x3x3, and then matmul it with our flattened kernel(3x3x3). This results in matmul between a 1x27 image and 27x1 kernel, resulting in a single scalar value. This scalar corresponds to a single pixel of the activation map after being added to the scalar bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a6085",
   "metadata": {},
   "source": [
    "Let's take an example. Start from inputs of dimension 16x3x32x32 where 16 is the batch size, 3 is the number of channels and 32x32 is the image size. So we have 16 rgb images of 32x32 resolution as input each batch. Consider a kernel size of 128x3x2x2 where 128 is the number of kernels, 3 represents rgb and 3x3 is the kernel size. \n",
    "\n",
    "How does im2col work in this case? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32d88c",
   "metadata": {},
   "source": [
    "Firstly, calculate the receptive field size or the output field size.\n",
    "\n",
    "O = ((I - K + 2P)/S) + 1\n",
    "\n",
    "This is the standard formula where:\n",
    "- I : Input image size (eg. 32x32)\n",
    "- K : Kernel size (eg. 3x3)\n",
    "- P : Zero Padding size (eg. 0 or 1 if we want O to be 32 = I)\n",
    "- S : Stride (eg. 1)\n",
    "- O : Output Activation size\n",
    "\n",
    "Here, \n",
    "\n",
    "O = ((32-3+0)/1) + 1 = 30\n",
    "\n",
    "So we get activation map of 30x30 per kernel.\n",
    "\n",
    "If we want the activation map to be same size of that of input, we have to introduce padding: Specifically same padding. \n",
    "\n",
    "In our example, same padding requires padding = 1\n",
    "\n",
    "Therefore we get, O = ((32-3+2)/1) + 1 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab4571",
   "metadata": {},
   "source": [
    "For now, let us assume the initial case with no Padding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60637dec",
   "metadata": {},
   "source": [
    "## Im2col Transformation Step-by-Step\n",
    "\n",
    "### Given:\n",
    "- Input: (16, 3, 32, 32) - 16 batches, 3 channels, 32×32 images\n",
    "- Kernels: (128, 3, 3, 3) - 128 output channels/kernels/activation maps, 3 input channels, 3×3 spatial\n",
    "- Output size: O = ((32 - 3 + 0) / 1) + 1 = **30×30**\n",
    "\n",
    "### Step 1: Extract All Receptive Fields\n",
    "\n",
    "For each image in the batch:\n",
    "- Each receptive field: 3×3×3 = **27 elements**\n",
    "- Number of positions: 30×30 = **900 positions**\n",
    "- Total number of flattened matrices that represent all positions: **(900, 27)** (But this flatenning requires special handling so that we differentiate from 27 contigious memory of the image, and 27 neighbouring pixels that constitute a receptive field.)\n",
    "\n",
    "For the entire batch (16 images):\n",
    "- We stack all of them vertically (16 × 900, 27) = **(14,400, 27)**\n",
    "\n",
    "### Step 2: Flatten All 128 Kernels\n",
    "\n",
    "- Each kernel: 3×3×3 = 27 elements\n",
    "- Kernels shape: **(27, 128)**\n",
    "\n",
    "Why? 27 weights for each 128 kernels. \n",
    "\n",
    "### Step 3: Giant MatMul\n",
    "\n",
    "(14,400, 27) @ (27, 128) = **(14,400, 128)**\n",
    "\n",
    "### Step 4: Reshape and Add Bias\n",
    "\n",
    "Reshape (14,400, 128) → (16, 128, 30, 30)\n",
    "Add bias (128,) → broadcasts to (16, 128, 30, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f627a",
   "metadata": {},
   "source": [
    "## So lets draw some conclusions first!\n",
    "\n",
    "1. We need special type of matrix flatenning such that all pixels of local receptive fields(3x3x3 = 27) are in one dimension(x, 27) and all such local receptive fields(30x30 = 900) are in another, batch dimension(900, x) which represents the number of such possible receptive fields. This corresponds to number of pixels in activation map. Finally we need to consider all the receptive fields of all images in the batch. This doesnot create new dimension (not, eg. 16x900x27), but we stack all the receptive fields of all the images vertically. (i.e 900x16 = 14,400). Therefore we get final flatenned 2D matrix of shape = 14400, 27.\n",
    "\n",
    "    ## Therefore:\n",
    "    Local receptive field pixels must be arranged non contigiously relative to the image.\n",
    "\n",
    "    eg.\n",
    "\n",
    "    11  12  13\n",
    "\n",
    "    21  22  23\n",
    "\n",
    "    31  32  33\n",
    "\n",
    "    should not be flattened as: \n",
    "\n",
    "    [11, 12, 13, 14],\n",
    "        \n",
    "    [13, 21, 22, 23], \n",
    "\n",
    "\n",
    "    [22, 23, 31, 32], \n",
    "\n",
    "    [31, 32, 33, 11] \n",
    "\n",
    "    Shape(4x4)\n",
    "\n",
    "    or,\n",
    "\n",
    "    [1,2,3,4,5,6,7,8,9] : Shape (9)\n",
    "\n",
    "    But as:\n",
    "    \n",
    "    [11, 12, 21, 22],\n",
    "\n",
    "    [12, 13, 22, 23],\n",
    "\n",
    "    [21, 22, 23, 31],\n",
    "\n",
    "    [22, 23, 32, 33]\n",
    "\n",
    "    Shape(4x4)\n",
    "\n",
    "\n",
    "2. To define our convolution layer, we need to know some parameters:\n",
    "- Depth/No. of Channels of Kernel which corresponds to input channels(in_channels)\n",
    "- Depth/No. of Channels of Activation/Output which corresponds to number of kernels (out_channels)\n",
    "- Kernel size (kernel_size eg.(2) -> 2x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "019b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor:\n",
    "    def __init__(self, fromArray=np.zeros((2,2)), _children = (), _operation = ''):\n",
    "        fromArray = fromArray if isinstance(fromArray, np.ndarray) else np.array(fromArray)\n",
    "        #assert len(fromArray.shape) == 2, \"Only 2D Tensors or Scalar to 2D Supported!\"\n",
    "        self.matrix = fromArray\n",
    "        #self.rows = fromArray.shape[0]\n",
    "        #self.columns = fromArray.shape[1]\n",
    "        self.shape = fromArray.shape\n",
    "        self._prev = set(_children)\n",
    "        self._operation = _operation\n",
    "        self._backward = lambda : None\n",
    "        self.grad = None\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor Values = {self.matrix}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def zeros(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = np.zeros(shape, dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.random.randn(*shape) * 0.1).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def he_init(cls, shape, fan_in, dtype=np.float32):\n",
    "        t = tensor()\n",
    "        std = np.sqrt(2.0 / fan_in)\n",
    "        t.matrix = (np.random.randn(*shape) * std).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def const(cls, shape, constant=1, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.full(shape, constant)).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    #Operations\n",
    "    def __add__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix + other.matrix\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            out2 = other.return_unbroadcasted(out)\n",
    "            self.grad += out1 #Derivation in the notes. \n",
    "            other.grad += out2\n",
    "        out = tensor(out_matrix, (self, other), '+')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self + (-1 * other)\n",
    "    \n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return other + (-1 * other)\n",
    "    \n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix * other.matrix\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(out.grad) if other.grad is None else other.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            out2 = other.return_unbroadcasted(out)\n",
    "            self.grad += out1* other.matrix #Derivation in the notes. \n",
    "            other.grad += out2 * self.matrix\n",
    "\n",
    "        out = tensor(out_matrix, (self, other), '*')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self*other\n",
    "    \n",
    "    '''\n",
    "    batch multiplication might cause shape broadcasts.\n",
    "    eg. (3,2,2) @ (1,2,3) = (3,2,3)\n",
    "    this is similar to our element wise operations\n",
    "    thus we should be handling this the same way we did for elementwise operations\n",
    "    But, for now, we would be working in a controlled way (Even for CNNS)\n",
    "    and wouldn't need this handling.\n",
    "    '''\n",
    "    def __matmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        assert other.shape[-2] == self.shape[-1], \"Dimension Unsupported for @\"\n",
    "        out_matrix = self.matrix @ other.matrix\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            self.grad += out.grad @ (other.matrix).swapaxes(-2,-1)#Derivation in the notes.\n",
    "            other.grad += (self.matrix).swapaxes(-2,-1) @ out.grad \n",
    "        out = tensor(out_matrix, (self, other), '@')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "\n",
    "    #I and thus we should learn at this point that to make our class compatible for ND tensors,\n",
    "    #We need the matrix multiplication and Transpose backward to change\n",
    "    #For higher dimensions, matmul = batch matmul where multiplication is done \n",
    "    #along each and every batches of 2D matrix. \n",
    "    #eg. If we have (2,3,3) shape tensor, it implies there are two batches of (3,3) matrices\n",
    "    #similarly, (2,3,3,2) shape = 2x3 batches of 3x2 matrices.\n",
    "    #matrix multiplication, (2,3,3) @ (2,3,2) = (2,3,2)\n",
    "    def swap_axes(self, axis1, axis2):\n",
    "        out_matrix = self.matrix.swapaxes(axis1, axis2)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad.swapaxes(axis1,axis2)) if self.grad is None else self.grad\n",
    "            self.grad += (out.grad).swapaxes(axis1,axis2) #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def transpose(self):\n",
    "        out_matrix = self.matrix.transpose()\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad.transpose()) if self.grad is None else self.grad\n",
    "            self.grad += (out.grad).transpose() #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __rmatmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        return other @ self\n",
    "    \n",
    "    def __pow__(self, N):\n",
    "        assert isinstance(N, int | float), \"Can only power up by scalars!\"\n",
    "        out_matrix = self.matrix ** N\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            self.grad += N * (self.matrix ** (N-1)) * out1\n",
    "        \n",
    "        out = tensor(out_matrix, _children=(self, ), _operation=\"**\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self * (other**-1)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return other * (self**-1)\n",
    "    \n",
    "    def sum(self):\n",
    "        out_matrix = np.array(([[self.matrix.sum()]]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * out.grad\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='sum()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def mean(self):\n",
    "        N = np.prod(self.shape)\n",
    "        out_matrix = np.array(([[self.matrix.sum()/(N)]]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * out.grad / N\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='mean()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def ReLU(self):\n",
    "        out_matrix = np.maximum(0,self.matrix)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (self.matrix > 0).astype(self.matrix.dtype) * out.grad\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"ReLU\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def reshape(self, shape):\n",
    "        assert isinstance(shape, tuple), f\"Can only reshape using shape tuples e.g. (3,3). Provided is {shape}\"\n",
    "        out_matrix = self.matrix.reshape(shape)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"reshape()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def flatten(self):\n",
    "        out_matrix = self.matrix.reshape(-1,np.prod(self.shape[1:]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"flatten()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    #Helper Functions\n",
    "    #def shape(self):\n",
    "     #   return (self.rows, self.columns)\n",
    "\n",
    "    def return_unbroadcasted(self, out):  \n",
    "        added_axis = []\n",
    "        stretched_axis = []\n",
    "        for index, (first_no, second_no) in enumerate(itertools.zip_longest(reversed(self.shape), reversed(out.shape))):\n",
    "            if first_no is None:\n",
    "                added_axis.append(index)\n",
    "            elif (first_no == 1) and (second_no > 1):\n",
    "                stretched_axis.append(index)\n",
    "        grad = out.grad\n",
    "        ndim = len(out.shape)\n",
    "        if stretched_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in stretched_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=True)\n",
    "        if added_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in added_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=False)\n",
    "        return grad\n",
    "\n",
    "    def checkOther(self, other):\n",
    "        if isinstance(other, int | float):\n",
    "            other = tensor.const(self.shape, other)\n",
    "        elif not isinstance(other, tensor):\n",
    "            other = tensor(other)\n",
    "        #assert other.shape == self.shape, \"Operand Tensor sizes dont match\"\n",
    "\n",
    "        return other\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.grad = None\n",
    "        \n",
    "    def backward(self):\n",
    "        self.grad = np.ones_like(self.matrix, dtype=float)\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for current in reversed(topo):\n",
    "\n",
    "            current._backward()\n",
    "\n",
    "    def exp(self):\n",
    "        out_matrix = np.exp(self.matrix)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out_matrix * out.grad  \n",
    "        \n",
    "        out = tensor(out_matrix, (self,), 'exp')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log(self, eps=1e-8):\n",
    "        clipped = np.clip(self.matrix, eps, None)  \n",
    "        out_matrix = np.log(clipped)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (1.0 / clipped) * out.grad \n",
    "        \n",
    "        out = tensor(out_matrix, (self,), 'log')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def softmax(self, axis=-1):\n",
    "        out_matrix = np.exp(self.matrix) / np.sum(np.exp(self.matrix), axis = axis, keepdims=True)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out_matrix*(out.grad - np.sum(out_matrix * out.grad, axis = axis, keepdims=True))\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'softmax')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    __array_ufunc__ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f24cb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size, stride):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            grad_6D = np.reshape(out.grad, shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w,))\n",
    "\n",
    "            #For each element in this 6D tensor, having 6D index, we have to calculate the coresponding 4D index.\n",
    "            #The formula has been conceptually derived in the notes.\n",
    "            #Here, we first generate all the indices of the 6D tensor and store each index dimension in separate list\n",
    "            #Then using the derived formula, we batch convert the 6D indices to 4D indices.\n",
    "\n",
    "            batch = np.arange(batch_size).reshape(batch_size,1,1,1,1,1)\n",
    "            field_h = np.arange(act_h).reshape(1,act_h,1,1,1,1)\n",
    "            field_w = np.arange(act_w).reshape(1,1,act_w,1,1,1)\n",
    "            channel = np.arange(channels).reshape(1,1,1,channels,1,1)\n",
    "            k_h = np.arange(kernel_h).reshape(1,1,1,1,kernel_h,1)\n",
    "            k_w = np.arange(kernel_w).reshape(1,1,1,1,1,kernel_w)\n",
    "\n",
    "            x = stride * field_h + k_h\n",
    "            y = stride * field_w + k_w\n",
    "\n",
    "            np.add.at(X.grad, (batch, channel, x, y), grad_6D)\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "51acf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  (16, 3, 5, 5)\n",
      "Output Shape:  (64, 27)\n"
     ]
    }
   ],
   "source": [
    "batch = tensor(np.random.randn(16, 3, 5, 5).astype(float))\n",
    "\n",
    "print(\"Input Shape: \", batch.shape)\n",
    "\n",
    "im2col = Conv2d.im2col(batch, 3, 2)\n",
    "\n",
    "print(\"Output Shape: \", im2col.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a5042",
   "metadata": {},
   "source": [
    "This was a valid approach. Elegant and shows the direct use of formula. But, we have an even more efficient approach. It involves slicing. In this method, instead of creating large index array which requires both time and memory, we can call 2 simple for loops to loop over the kernel sizes and slice the out.grad array for each position of the kernel index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a07f9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=2):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = tensor.random((out_channels, ))\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def __call__(self, X : tensor, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        X_col, act_h, act_w = Conv2d.im2col(X, kernel_size=self.kernel_size, stride=stride)\n",
    "        K_col_shape = (self.out_channels, self.kernel_size*self.kernel_size*self.in_channels)\n",
    "        K_col = self.kernel.reshape(K_col_shape).transpose()\n",
    "        Y_col = X_col @ K_col + self.bias\n",
    "        Y = Y_col.reshape((batch_size, self.out_channels, act_h, act_w))\n",
    "        pooled = Conv2d.maxpool2d(Y)\n",
    "        return pooled\n",
    "        \n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size=2, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            \n",
    "            grad_6D = out.grad.reshape(batch_size, act_h, act_w, channels, kernel_h, kernel_w)\n",
    "\n",
    "            for i in range(kernel_h):\n",
    "                for j in range(kernel_w):\n",
    "                    grad_slice = grad_6D[:, :, :, :, i, j]\n",
    "                    \n",
    "                    grad_slice_transposed = grad_slice.transpose(0, 3, 1, 2)\n",
    "                    \n",
    "                    X.grad[:, :, \n",
    "                        i : i + act_h * stride : stride, \n",
    "                        j : j + act_w * stride : stride\n",
    "                    ] += grad_slice_transposed\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out, act_h, act_w\n",
    "    \n",
    "    @classmethod\n",
    "    def maxpool2d(cls, Y: tensor, pool_size=2, stride=1):   \n",
    "        batch_number = Y.shape[0]\n",
    "        filters = Y.shape[1]\n",
    "        image_height = Y.shape[-2] #Rows\n",
    "        image_width = Y.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        pool_h = pool_size\n",
    "        pool_w = pool_size\n",
    "\n",
    "        pooled_h = (((image_height - pool_h)//stride) + 1) #height of activation\n",
    "        pooled_w = (((image_width - pool_w)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = Y.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            Y.matrix,\n",
    "                            shape=(batch_number, pooled_h, pooled_w, filters, pool_h, pool_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        intermediate_5D = np.reshape(intermediate_6D, (batch_number, filters, pooled_h, pooled_w, pool_h * pool_w))\n",
    "\n",
    "\n",
    "        out_matrix = np.max(intermediate_5D, axis = -1)\n",
    "        IndexA_for5D = np.argmax(intermediate_5D, axis = -1)\n",
    "\n",
    "        def _backward():\n",
    "            # Recover window position (i, j) from flat index in last dim\n",
    "            Y.grad = np.zeros_like(Y.matrix) if Y.grad is None else Y.grad\n",
    "            flat_idx = IndexA_for5D  # (B, F, pooled_h, pooled_w)\n",
    "            i = flat_idx // pool_w\n",
    "            j = flat_idx % pool_w\n",
    "\n",
    "            # Build grids for batch, filter, and pooled positions\n",
    "            b_grid = np.arange(batch_number).reshape(batch_number, 1, 1, 1)\n",
    "            f_grid = np.arange(filters).reshape(1, filters, 1, 1)\n",
    "            ph_grid = np.arange(pooled_h).reshape(1, 1, pooled_h, 1)\n",
    "            pw_grid = np.arange(pooled_w).reshape(1, 1, 1, pooled_w)\n",
    "\n",
    "            # Broadcast all to shape (B, F, pooled_h, pooled_w)\n",
    "            b_idx = np.broadcast_to(b_grid, flat_idx.shape)\n",
    "            f_idx = np.broadcast_to(f_grid, flat_idx.shape)\n",
    "            ph = np.broadcast_to(ph_grid, flat_idx.shape)\n",
    "            pw = np.broadcast_to(pw_grid, flat_idx.shape)\n",
    "\n",
    "            # Compute actual positions in Y where max values came from\n",
    "            h_idx = stride * ph + i\n",
    "            w_idx = stride * pw + j\n",
    "\n",
    "            # Accumulate gradients using 4D indexing\n",
    "            np.add.at(Y.grad, (b_idx.ravel(), f_idx.ravel(), h_idx.ravel(), w_idx.ravel()), out.grad.ravel())\n",
    "\n",
    "        out = tensor(out_matrix, _children=(Y, ), _operation=\"maxpool\")\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "80ad2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradient:\n",
      " [[ 0.          0.16558826  0.26603022  0.        ]\n",
      " [ 0.         -0.12948838 -0.21422252  0.13301511]\n",
      " [ 0.08279413  0.13301511 -0.06474419 -0.14850833]\n",
      " [-0.06474419 -0.14850833  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Test im2col gradient via Conv2d layer\n",
    "X = tensor(np.random.randn(1, 1, 4, 4))\n",
    "layer = Conv2d(in_channels=1, out_channels=1, kernel_size=2)\n",
    "Y = layer(X, stride=1)\n",
    "Y.backward()\n",
    "print(\"Input gradient:\\n\", X.grad[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6da9de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/0mwc7nyn64x7k2f0jlg9hs300000gn/T/ipykernel_4904/2651310694.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 16 + 1) instead\n",
      "  numbers = np.random.random_integers(0,16, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = np.random.random_integers(0,16, 16)\n",
    "Y = numbers.reshape(16,1)\n",
    "act_h = 4\n",
    "act_w = 4\n",
    "istrides = Y.strides\n",
    "istrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d01be75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradient:\n",
      " [[ 0.          0.          0.          0.        ]\n",
      " [ 0.19496737  0.31884017  0.12387279  0.        ]\n",
      " [ 0.13988314  0.32095182  0.18106868  0.        ]\n",
      " [-0.05508423  0.00211165  0.05719589  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Test maxpool gradient via Conv2d layer\n",
    "X = tensor(np.random.randn(1, 1, 4, 4))\n",
    "layer = Conv2d(in_channels=1, out_channels=1, kernel_size=2)\n",
    "Y = layer(X, stride=1)\n",
    "Y.backward()\n",
    "print(\"Input gradient:\\n\", X.grad[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "62a6478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=2, stride=1):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "        #fan_in = in_channels * kernel_size * kernel_size\n",
    "        #self.kernel = tensor.he_init((out_channels, in_channels, kernel_size, kernel_size), fan_in)\n",
    "        self.bias = tensor.zeros((out_channels, ))\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.stride = stride\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.kernel, self.bias]\n",
    "\n",
    "    def __call__(self, X : tensor):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        X_col, act_h, act_w = Conv2d.im2col(X, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        K_col_shape = (self.out_channels, self.kernel_size*self.kernel_size*self.in_channels)\n",
    "        K_col = self.kernel.reshape(K_col_shape).transpose()\n",
    "        Y_col = X_col @ K_col + self.bias\n",
    "        Y = Y_col.reshape((batch_size, self.out_channels, act_h, act_w))\n",
    "        return Y\n",
    "        \n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size=2, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            \n",
    "            grad_6D = out.grad.reshape(batch_size, act_h, act_w, channels, kernel_h, kernel_w)\n",
    "            for i in range(kernel_h):\n",
    "                for j in range(kernel_w):\n",
    "                    grad_slice = grad_6D[:, :, :, :, i, j]\n",
    "                    \n",
    "                    grad_slice_transposed = grad_slice.transpose(0, 3, 1, 2)\n",
    "                    X.grad[:, :, \n",
    "                        i : i + act_h * stride : stride, \n",
    "                        j : j + act_w * stride : stride\n",
    "                    ] += grad_slice_transposed\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out, act_h, act_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "39002f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maxpool2D:\n",
    "    def __init__(self, in_channels, pool_size = 2, stride = 1):\n",
    "        self.in_channels = in_channels\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def __call__(self, Y: tensor):\n",
    "\n",
    "        batch_number = Y.shape[0]\n",
    "        filters = Y.shape[1]\n",
    "        image_height = Y.shape[-2] #Rows\n",
    "        image_width = Y.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        pool_h = self.pool_size\n",
    "        pool_w = self.pool_size\n",
    "\n",
    "        pooled_h = (((image_height - pool_h)//self.stride) + 1) #height of activation\n",
    "        pooled_w = (((image_width - pool_w)//self.stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = Y.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            Y.matrix,\n",
    "                            shape=(batch_number, pooled_h, pooled_w, filters, pool_h, pool_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * self.stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * self.stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        intermediate_6D_transposed = intermediate_6D.transpose(0, 3, 1, 2, 4, 5)\n",
    "        intermediate_5D = intermediate_6D_transposed.reshape(batch_number, filters, pooled_h, pooled_w, pool_h * pool_w)\n",
    "\n",
    "        out_matrix = np.max(intermediate_5D, axis=-1)\n",
    "        IndexA_for5D = np.argmax(intermediate_5D, axis=-1)\n",
    "\n",
    "        def _backward():\n",
    "            # Recover window position (i, j) from flat index in last dim\n",
    "            Y.grad = np.zeros_like(Y.matrix) if Y.grad is None else Y.grad\n",
    "            flat_idx = IndexA_for5D  # (B, F, pooled_h, pooled_w)\n",
    "            i = flat_idx // pool_w\n",
    "            j = flat_idx % pool_w\n",
    "\n",
    "            # Build grids for batch, filter, and pooled positions\n",
    "            b_grid = np.arange(batch_number).reshape(batch_number, 1, 1, 1)\n",
    "            f_grid = np.arange(filters).reshape(1, filters, 1, 1)\n",
    "            ph_grid = np.arange(pooled_h).reshape(1, 1, pooled_h, 1)\n",
    "            pw_grid = np.arange(pooled_w).reshape(1, 1, 1, pooled_w)\n",
    "\n",
    "            # Broadcast all to shape (B, F, pooled_h, pooled_w)\n",
    "            b_idx = np.broadcast_to(b_grid, flat_idx.shape)\n",
    "            f_idx = np.broadcast_to(f_grid, flat_idx.shape)\n",
    "            ph = np.broadcast_to(ph_grid, flat_idx.shape)\n",
    "            pw = np.broadcast_to(pw_grid, flat_idx.shape)\n",
    "\n",
    "            # Compute actual positions in Y where max values came from\n",
    "            h_idx = self.stride * ph + i\n",
    "            w_idx = self.stride * pw + j\n",
    "\n",
    "            # Accumulate gradients using 4D indexing\n",
    "            np.add.at(Y.grad, (b_idx.ravel(), f_idx.ravel(), h_idx.ravel(), w_idx.ravel()), out.grad.ravel())\n",
    "\n",
    "        out = tensor(out_matrix, _children=(Y, ), _operation=\"maxpool\")\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "97cc1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \n",
    "        self.bias = tensor.zeros((out_features, 1))\n",
    "        # He initialization: fan_in = in_features\n",
    "        #self.weights = tensor.he_init((out_features, in_features), in_features)\n",
    "        self.weights = tensor.random((out_features, in_features))\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.bias]\n",
    "\n",
    "    def __call__(self, X:tensor):\n",
    "        return (self.weights @ X) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "20424c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, in_channels, layers, kernels_in_layers, kernels_shape, conv_strides, pool_shape, pool_strides, FCL_weights):\n",
    "\n",
    "        self.FCL_weights = FCL_weights\n",
    "        self.layers = layers\n",
    "        self.conv_layers = [Conv2d(in_channels[layer], kernels_in_layers[layer], kernels_shape[layer], conv_strides[layer]) for layer in range(layers)]\n",
    "        self.pool_layers = [maxpool2D(kernels_in_layers[layer], pool_shape[layer], pool_strides[layer]) for layer in range(layers)]\n",
    "        self.FC_layers = [None for _ in range(layers+1)]\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in range(self.layers):\n",
    "            params.extend(self.conv_layers[layer].parameters())\n",
    "            params.extend(self.FC_layers[layer].parameters())\n",
    "        params.extend(self.FC_layers[layer+1].parameters())\n",
    "        return params\n",
    "\n",
    "    def __call__(self, X:tensor):\n",
    "        b = X\n",
    "        for layer in range(self.layers):\n",
    "            a_ = self.conv_layers[layer](b)\n",
    "            a = a_.ReLU()\n",
    "            b = self.pool_layers[layer](a)\n",
    "        \n",
    "        c:tensor = b.reshape((X.shape[0], -1)).transpose()\n",
    "        if self.FC_layers[0] is None:\n",
    "            self.FC_layers[0] = FC(c.shape[0], self.FCL_weights[0])\n",
    "\n",
    "        for layer in range(self.layers+1):\n",
    "            if self.FC_layers[layer] is None:\n",
    "                self.FC_layers[layer] = FC(self.FCL_weights[layer-1], self.FCL_weights[layer])\n",
    "\n",
    "            c = self.FC_layers[layer](c)\n",
    "            \n",
    "            if layer < self.layers:\n",
    "                c = c.ReLU()\n",
    "        \n",
    "        out = c.transpose()\n",
    "        return out\n",
    "    \n",
    "    @classmethod\n",
    "    def cross_entropy_loss(cls, ypredicted: tensor, ytrue, batch_size):\n",
    "        ytrue =  tensor(ytrue) if not isinstance(ytrue, tensor) else ytrue\n",
    "        ypredicted = ypredicted.softmax(axis=-1)\n",
    "        cross_entropy = -1 * ypredicted.log()\n",
    "        #loss = ((ytrue * cross_entropy).sum())/batch_size\n",
    "        loss = ((ytrue * cross_entropy).sum())\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 10, lr = 0.001, batch_size = 32):\n",
    "        lossT = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            n_batches = 0\n",
    "            perm = np.random.permutation(len(X_train))\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                idx = perm[i:i+batch_size]\n",
    "                xb = tensor(X_train[idx])             \n",
    "                yb = tensor(y_train[idx]) \n",
    "\n",
    "                y_predicted = self(xb)\n",
    "                ce_loss = CNN.cross_entropy_loss(y_predicted, yb, len(idx))\n",
    "                ce_loss.backward()\n",
    "\n",
    "                for param in self.parameters():\n",
    "                    if param.grad is not None:\n",
    "\n",
    "                        grad_clipped = np.clip(param.grad, -1.0, 1.0)\n",
    "                        param.matrix -= lr * grad_clipped\n",
    "                        param.grad = None\n",
    "                \n",
    "                epoch_loss += ce_loss.matrix.flatten()[0]\n",
    "                n_batches += 1\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
    "            lossT.append((epoch, avg_loss))\n",
    "\n",
    "        return lossT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ba188a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor Values = [[ 1.37541    -0.17973997 -0.5400962  -0.3545546   2.3042114   0.67399174\n",
       "  -1.4384911   0.89020795 -0.11354592  0.5103045 ]\n",
       " [ 1.0008098  -0.99008155 -0.56224483 -0.6605275   2.5096958   0.9243122\n",
       "  -1.1521055   1.4019393  -0.77530885  0.655017  ]\n",
       " [ 1.0949072  -0.03747508 -0.3775244  -0.21293691  1.5070676   0.5822945\n",
       "  -1.4455955   1.1064692  -0.1782994   0.9344257 ]\n",
       " [ 1.3523557  -0.34198967 -0.25011295 -0.42021936  1.9192302   0.7020867\n",
       "  -1.3195586   1.1450962   0.47290972  0.6088739 ]]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tensor.random((4, 3, 32, 32))\n",
    "c = CNN((3,5, ), 2, (5, 16, ), (5, 5, ), (1, 1, ), (2, 2, ), (1, 1, ), (128, 64, 10, ))\n",
    "out = c(X)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b9119f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:, np.newaxis, :, :].astype(np.float32) / 255.0  \n",
    "X_test = X_test[:, np.newaxis, :, :].astype(np.float32) / 255.0\n",
    "Y_train = np.zeros((y_train.size, 10))\n",
    "Y_train[np.arange(y_train.size), y_train] = 1\n",
    "Y_test = np.zeros((y_test.size, 10))\n",
    "Y_test[np.arange(y_test.size), y_test] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ec9327d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 67.764360\n",
      "Epoch 2/50, Loss: 41.843807\n",
      "Epoch 3/50, Loss: 24.200884\n",
      "Epoch 4/50, Loss: 17.790467\n",
      "Epoch 5/50, Loss: 12.652607\n",
      "Epoch 6/50, Loss: 9.882604\n",
      "Epoch 7/50, Loss: 7.376572\n",
      "Epoch 8/50, Loss: 5.709124\n",
      "Epoch 9/50, Loss: 4.334053\n",
      "Epoch 10/50, Loss: 3.495332\n",
      "Epoch 11/50, Loss: 1.782920\n",
      "Epoch 12/50, Loss: 2.866913\n",
      "Epoch 13/50, Loss: 1.205334\n",
      "Epoch 14/50, Loss: 0.183684\n",
      "Epoch 15/50, Loss: 0.485346\n",
      "Epoch 16/50, Loss: 0.042181\n",
      "Epoch 17/50, Loss: 0.014020\n",
      "Epoch 18/50, Loss: 0.009922\n",
      "Epoch 19/50, Loss: 0.007908\n",
      "Epoch 20/50, Loss: 0.006635\n",
      "Epoch 21/50, Loss: 0.005751\n",
      "Epoch 22/50, Loss: 0.005063\n",
      "Epoch 23/50, Loss: 0.004540\n",
      "Epoch 24/50, Loss: 0.004113\n",
      "Epoch 25/50, Loss: 0.003762\n",
      "Epoch 26/50, Loss: 0.003483\n",
      "Epoch 27/50, Loss: 0.003231\n",
      "Epoch 28/50, Loss: 0.003011\n",
      "Epoch 29/50, Loss: 0.002833\n",
      "Epoch 30/50, Loss: 0.002668\n",
      "Epoch 31/50, Loss: 0.002520\n",
      "Epoch 32/50, Loss: 0.002391\n",
      "Epoch 33/50, Loss: 0.002269\n",
      "Epoch 34/50, Loss: 0.002167\n",
      "Epoch 35/50, Loss: 0.002065\n",
      "Epoch 36/50, Loss: 0.001976\n",
      "Epoch 37/50, Loss: 0.001896\n",
      "Epoch 38/50, Loss: 0.001820\n",
      "Epoch 39/50, Loss: 0.001752\n",
      "Epoch 40/50, Loss: 0.001687\n",
      "Epoch 41/50, Loss: 0.001630\n",
      "Epoch 42/50, Loss: 0.001574\n",
      "Epoch 43/50, Loss: 0.001522\n",
      "Epoch 44/50, Loss: 0.001475\n",
      "Epoch 45/50, Loss: 0.001429\n",
      "Epoch 46/50, Loss: 0.001386\n",
      "Epoch 47/50, Loss: 0.001345\n",
      "Epoch 48/50, Loss: 0.001307\n",
      "Epoch 49/50, Loss: 0.001270\n",
      "Epoch 50/50, Loss: 0.001236\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final accuracy on 10 samples: 100.0%\n"
     ]
    }
   ],
   "source": [
    "c = CNN(\n",
    "    in_channels=(1, 5),           \n",
    "    layers=2,                      \n",
    "    kernels_in_layers=(5, 16),    \n",
    "    kernels_shape=(5, 5),         \n",
    "    conv_strides=(1, 1),          \n",
    "    pool_shape=(2, 2),            \n",
    "    pool_strides=(2, 2),          \n",
    "    FCL_weights=(128, 64, 10)     \n",
    ")\n",
    "\n",
    "loss = c.fit(X_train[:1000], Y_train[:1000], epochs=50, lr=0.01, batch_size=32)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "epochs, losses = zip(*loss)\n",
    "plt.plot(epochs, losses)\n",
    "plt.show()\n",
    "\n",
    "# Check predictions\n",
    "xtest = X_train[:10]\n",
    "ytest = Y_train[:10]\n",
    "ypred = c(tensor(xtest))\n",
    "probs = ypred.softmax()\n",
    "pred_classes = np.argmax(probs.matrix, axis=1)\n",
    "true_classes = np.argmax(ytest, axis=1)\n",
    "print(f\"\\nFinal accuracy on 10 samples: {(pred_classes == true_classes).mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a1a1c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGdVJREFUeJzt3QuMFdXhP/Czi7CiskuRx7ICK4hC64O2FpCo+CIgbYioaaQ1DbZGCgVfVG2oVbRtsv1hYo0txZo0oqmKNS2+YkgVBWILGrCUGClxCbIYASsJuzwKkt35Z+b3Z3+sgvZedvfcvffzSSZ3771zdobD2fneM3Pm3LIkSZIAAJ2svLM3CAACCIBo9IAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUZwQCkxLS0v48MMPQ69evUJZWVns3QEgR+n8Bnv27Ak1NTWhvLy86wRQGj6DBw+OvRsAHKdt27aFQYMGdZ1TcGnPB4Cu74uO5x0WQAsXLgynn356OPHEE8PYsWPDW2+99V+Vc9oNoDh80fG8QwLomWeeCXPnzg3z588Pb7/9dhg1alSYNGlS+OijjzpicwB0RUkHGDNmTDJ79uzW583NzUlNTU1SV1f3hWUbGxvT2bkt6kAb0Aa0gdC16yA9nn+edu8BffLJJ2HdunVhwoQJra+loyDS56tXr/7M+gcPHgxNTU1tFgCKX7sH0Mcffxyam5vDgAED2ryePt+xY8dn1q+rqwtVVVWtixFwAKUh+ii4efPmhcbGxtYlHbYHQPFr9/uA+vbtG7p16xZ27tzZ5vX0eXV19WfWr6ioyBYASku794B69OgRzj///LB8+fI2sxukz8eNG9femwOgi+qQmRDSIdjTp08P3/jGN8KYMWPCQw89FPbt2xe+//3vd8TmAOiCOiSArrvuuvDvf/873HvvvdnAg69+9ath2bJlnxmYAEDpKkvHYocCkg7DTkfDAdC1pQPLKisrC3cUHAClSQABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQSAAAKgdOgBARCFAAIgihPibBYK08knn5xzmQceeCDnMj/84Q9zLrNu3bqcy3z7298O+di6dWte5SAXekAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIIqyJEmSUECamppCVVVV7N2gRA0fPjznMhs3bgydobw898+Lt9xyS17bWrhwYV7l4EiNjY2hsrIyHIseEABRCCAAiiOA7rvvvlBWVtZmGTlyZHtvBoAurkO+kO7ss88Or7766v9t5ATfewdAWx2SDGngVFdXd8SvBqBIdMg1oPfeey/U1NSEYcOGheuvvz40NDQcc92DBw9mI9+OXAAofu0eQGPHjg2LFy8Oy5YtC4sWLQpbtmwJF198cdizZ89R16+rq8uGXR9eBg8e3N67BEAp3ge0e/fuUFtbGx588MFw4403HrUHlC6HpT0gIUQs7gP6X+4DojPuA+rw0QG9e/cOZ511Vqivrz/q+xUVFdkCQGnp8PuA9u7dGzZv3hwGDhzY0ZsCoJQD6I477ggrV64M77//fvj73/8err766tCtW7fwne98p703BUAX1u6n4D744IMsbHbt2hX69esXLrroorBmzZrsZwDosABasmRJe/9KyFm+H3gef/xxtQ2dxFxwAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiCKDv9COjhet9xyS85lpk6dmte2xowZE4rJ+PHj8ypXXp77Z9N//vOfOZdZtWpVzmUoHnpAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFGVJkiShgDQ1NYWqqqrYu0EBaW5uzrlMS0tLKDb5zFDdmfWwdevWnMtcd911OZdZt25dzmWIo7GxMVRWVh7zfT0gAKIQQAAIIABKhx4QAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFGcEGezlKqXX365UybhLEa7du3KuczevXvz2lZtbW3OZYYOHZpzmbfeeivnMt26dcu5DIXJXzYAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiMJkpOTtkksuybnMiBEjci7T0tLSKWU60yOPPJJzmb/+9a85l2lsbAz5uPzyy3Muc/fdd4fOMGvWrJzLLFq0qEP2heOjBwRAFAIIgK4RQKtWrQpTpkwJNTU1oaysLDz33HNt3k+SJNx7771h4MCBoWfPnmHChAnhvffea899BqAUA2jfvn1h1KhRYeHChUd9f8GCBeHhhx/OznG/+eab4eSTTw6TJk0KBw4caI/9BaBUByFMnjw5W44m7f089NBD4Wc/+1m46qqrsteeeOKJMGDAgKynNG3atOPfYwCKQrteA9qyZUvYsWNHdtrtsKqqqjB27NiwevXqo5Y5ePBgaGpqarMAUPzaNYDS8EmlPZ4jpc8Pv/dpdXV1WUgdXgYPHtyeuwRAgYo+Cm7evHnZvQqHl23btsXeJQC6WgBVV1dnjzt37mzzevr88HufVlFRESorK9ssABS/dg2goUOHZkGzfPny1tfSazrpaLhx48a156YAKLVRcHv37g319fVtBh6sX78+9OnTJwwZMiTcdttt4Ze//GU488wzs0C65557snuGpk6d2t77DkApBdDatWvDZZdd1vp87ty52eP06dPD4sWLw1133ZXdKzRjxoywe/fucNFFF4Vly5aFE088sX33HIAurSxJb94pIOkpu3Q0HJ3n9NNPz6vcsYbWf56+ffvmXKa8vLzTJiPdunVrzmX+/Oc/51zm/vvvz7nM/v37Q2epra3tlPbQr1+/nMvkc1N7OjtLPn7729/mXObQoUN5basYpQPLPu+6fvRRcACUJgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIwGzZh+PDhedXCxo0bO6X28pkN+/XXX89rW9OmTcu5zMcff5zXtorNzTffnHOZBx98sKBnRx85cmTOZTZv3pzXtoqR2bABKEhOwQEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUJ8TZLPz31q5dm3N1/eAHP8irik0smr8XXngh5zLXX399zmVGjx6dcxkKkx4QAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIjCZKTkrby8cz6/jB07tlO2w/EpKyvrlDbUWe0udd999+Vc5nvf+16H7Esx0gMCIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFGYjJQwc+bMvGqhpaVF7dFqypQpOdfG1772tU5pd/m21XwmI+W/pwcEQBQCCICuEUCrVq3Kuto1NTXZ938899xzbd6/4YYbstePXK688sr23GcASjGA9u3bF0aNGhUWLlx4zHXSwNm+fXvr8vTTTx/vfgJQ6oMQJk+enC2fp6KiIlRXVx/PfgFQ5DrkGtCKFStC//79w4gRI8KsWbPCrl27jrnuwYMHQ1NTU5sFgOLX7gGUnn574oknwvLly8P//M//hJUrV2Y9pubm5qOuX1dXF6qqqlqXwYMHt/cuAVAK9wFNmzat9edzzz03nHfeeeGMM87IekVXXHHFZ9afN29emDt3buvztAckhACKX4cPwx42bFjo27dvqK+vP+b1osrKyjYLAMWvwwPogw8+yK4BDRw4sKM3BUAxn4Lbu3dvm97Mli1bwvr160OfPn2y5f777w/XXnttNgpu8+bN4a677grDhw8PkyZNau99B6CUAmjt2rXhsssua31++PrN9OnTw6JFi8KGDRvC448/Hnbv3p3drDpx4sTwi1/8IjvVBgCHlSVJkoQCkg5CSEfD0Xk2bdqU9/W9ztC9e/dO2U4x6tevX17lvvKVr+RcZsmSJTmXSa8P56q8PPcrBzt37gz5uOCCC3Iu09DQkNe2ilFjY+PnXtc3FxwAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAAVAcX8kNFI677747r3KzZ88Oher999/PuUz6dTH5MLN1x9IDAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRmIwUuoiXX3455zIjRowIxebdd9/Nucwbb7zRIfvC8dEDAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRmIyUUFZWllctlJd3zueXyZMnh87y6KOP5lympqYmdIZ86rulpSUUmylTpsTeBdqJHhAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiMJkpIRFixblVQsLFizolNp76aWXCnoSzkKe8LOQ9y31yCOPxN4FItIDAiAKAQRA4QdQXV1dGD16dOjVq1fo379/mDp1ati0aVObdQ4cOBBmz54dTj311HDKKaeEa6+9NuzcubO99xuAUgqglStXZuGyZs2a8Morr4RDhw6FiRMnhn379rWuc/vtt4cXX3wxPPvss9n6H374Ybjmmms6Yt8BKJVBCMuWLWvzfPHixVlPaN26dWH8+PGhsbEx/OEPfwhPPfVUuPzyy7N1HnvssfDlL385C60LLrigffcegNK8BpQGTqpPnz7ZYxpEaa9owoQJreuMHDkyDBkyJKxevfqov+PgwYOhqampzQJA8Ss/nuGdt912W7jwwgvDOeeck722Y8eO0KNHj9C7d+826w4YMCB771jXlaqqqlqXwYMH57tLAJRCAKXXgt55552wZMmS49qBefPmZT2pw8u2bduO6/cBUMQ3os6ZMye7OXDVqlVh0KBBra9XV1eHTz75JOzevbtNLygdBZe+dzQVFRXZAkBpyakHlCRJFj5Lly4Nr732Whg6dGib988///zQvXv3sHz58tbX0mHaDQ0NYdy4ce231wCUVg8oPe2WjnB7/vnns3uBDl/XSa/d9OzZM3u88cYbw9y5c7OBCZWVleHmm2/OwscIOADyDqDDc4ZdeumlbV5Ph1rfcMMN2c+//vWvQ3l5eXYDajrCbdKkSeF3v/tdLpsBoASUJel5tQKSDsNOe1J0ntra2rzKHWto/efp169fzmXSDzTFNglnPvKph3xnIdm4cWPOZWbMmJFzme3bt+dcZv/+/TmXIY50YFl6JuxYzAUHQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEYTZs8jZ+/Picy0ydOjXnMrfeemvOZcyG/b9uueWWkI+FCxfmVQ6OZDZsAAqSU3AARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhclIKXhXXnllzmVmzJiR17amTJmSc5kXXngh5zKPPvpozmXKyspyLvPuu++GfDQ0NORVDo5kMlIACpJTcABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFyUgB6BAmIwWgIDkFB0AUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAACj8AKqrqwujR48OvXr1Cv379w9Tp04NmzZtarPOpZdeGsrKytosM2fObO/9BqCUAmjlypVh9uzZYc2aNeGVV14Jhw4dChMnTgz79u1rs95NN90Utm/f3rosWLCgvfcbgC7uhFxWXrZsWZvnixcvznpC69atC+PHj299/aSTTgrV1dXtt5cAFJ3y4/261VSfPn3avP7kk0+Gvn37hnPOOSfMmzcv7N+//5i/4+DBg6GpqanNAkAJSPLU3NycfOtb30ouvPDCNq///ve/T5YtW5Zs2LAh+eMf/5icdtppydVXX33M3zN//vwk3Q2LOtAGtAFtIBRVHTQ2Nn5ujuQdQDNnzkxqa2uTbdu2fe56y5cvz3akvr7+qO8fOHAg28nDS/r7YleaRR1oA9qANhA6PIByugZ02Jw5c8JLL70UVq1aFQYNGvS5644dOzZ7rK+vD2ecccZn3q+oqMgWAEpLTgGU9phuvvnmsHTp0rBixYowdOjQLyyzfv367HHgwIH57yUApR1A6RDsp556Kjz//PPZvUA7duzIXq+qqgo9e/YMmzdvzt7/5je/GU499dSwYcOGcPvtt2cj5M4777yO+jcA0BXlct3nWOf5Hnvssez9hoaGZPz48UmfPn2SioqKZPjw4cmdd975hecBj5Su69yr8+/agDagDYQuXwdfdOwv+//BUjDSYdhpjwqAri29VaeysvKY75sLDoAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoCi6AkiSJvQsAdMLxvOACaM+ePbF3AYBOOJ6XJQXW5WhpaQkffvhh6NWrVygrK2vzXlNTUxg8eHDYtm1bqKysDKVKPagH7cHfRSEfH9JYScOnpqYmlJcfu59zQigw6c4OGjToc9dJK7WUA+gw9aAetAd/F4V6fKiqqvrCdQruFBwApUEAARBFlwqgioqKMH/+/OyxlKkH9aA9+LsohuNDwQ1CAKA0dKkeEADFQwABEIUAAiAKAQRAFF0mgBYuXBhOP/30cOKJJ4axY8eGt956K5Sa++67L5sd4shl5MiRoditWrUqTJkyJburOv03P/fcc23eT8fR3HvvvWHgwIGhZ8+eYcKECeG9994LpVYPN9xww2fax5VXXhmKSV1dXRg9enQ2U0r//v3D1KlTw6ZNm9qsc+DAgTB79uxw6qmnhlNOOSVce+21YefOnaHU6uHSSy/9THuYOXNmKCRdIoCeeeaZMHfu3Gxo4dtvvx1GjRoVJk2aFD766KNQas4+++ywffv21uWNN94IxW7fvn3Z/3n6IeRoFixYEB5++OHwyCOPhDfffDOcfPLJWftID0SlVA+pNHCObB9PP/10KCYrV67MwmXNmjXhlVdeCYcOHQoTJ07M6uaw22+/Pbz44ovh2WefzdZPp/a65pprQqnVQ+qmm25q0x7Sv5WCknQBY8aMSWbPnt36vLm5OampqUnq6uqSUjJ//vxk1KhRSSlLm+zSpUtbn7e0tCTV1dXJAw880Pra7t27k4qKiuTpp59OSqUeUtOnT0+uuuqqpJR89NFHWV2sXLmy9f++e/fuybPPPtu6zsaNG7N1Vq9enZRKPaQuueSS5NZbb00KWcH3gD755JOwbt267LTKkfPFpc9Xr14dSk16aik9BTNs2LBw/fXXh4aGhlDKtmzZEnbs2NGmfaRzUKWnaUuxfaxYsSI7JTNixIgwa9assGvXrlDMGhsbs8c+ffpkj+mxIu0NHNke0tPUQ4YMKer20PipejjsySefDH379g3nnHNOmDdvXti/f38oJAU3Gemnffzxx6G5uTkMGDCgzevp83/961+hlKQH1cWLF2cHl7Q7ff/994eLL744vPPOO9m54FKUhk/qaO3j8HulIj39lp5qGjp0aNi8eXP46U9/GiZPnpwdeLt16xaKTTpz/m233RYuvPDC7ACbSv/Pe/ToEXr37l0y7aHlKPWQ+u53vxtqa2uzD6wbNmwIP/nJT7LrRH/5y19CoSj4AOL/pAeTw84777wskNIG9qc//SnceOONqqrETZs2rfXnc889N2sjZ5xxRtYruuKKK0KxSa+BpB++SuE6aD71MGPGjDbtIR2kk7aD9MNJ2i4KQcGfgku7j+mnt0+PYkmfV1dXh1KWfso766yzQn19fShVh9uA9vFZ6Wna9O+nGNvHnDlzwksvvRRef/31Nl/fkraH9LT97t27S+J4MecY9XA06QfWVCG1h4IPoLQ7ff7554fly5e36XKmz8eNGxdK2d69e7NPM+knm1KVnm5KDyxHto/0C7nS0XCl3j4++OCD7BpQMbWPdPxFetBdunRpeO2117L//yOlx4ru3bu3aQ/paaf0WmkxtYfkC+rhaNavX589FlR7SLqAJUuWZKOaFi9enLz77rvJjBkzkt69eyc7duxISsmPf/zjZMWKFcmWLVuSv/3tb8mECROSvn37ZiNgitmePXuSf/zjH9mSNtkHH3ww+3nr1q3Z+7/61a+y9vD8888nGzZsyEaCDR06NPnPf/6TlEo9pO/dcccd2UivtH28+uqryde//vXkzDPPTA4cOJAUi1mzZiVVVVXZ38H27dtbl/3797euM3PmzGTIkCHJa6+9lqxduzYZN25cthSTWV9QD/X19cnPf/7z7N+ftof0b2PYsGHJ+PHjk0LSJQIo9Zvf/CZrVD169MiGZa9ZsyYpNdddd10ycODArA5OO+207Hna0Ird66+/nh1wP72kw44PD8W+5557kgEDBmQfVK644opk06ZNSSnVQ3rgmThxYtKvX79sGHJtbW1y0003Fd2HtKP9+9Plsccea10n/eDxox/9KPnSl76UnHTSScnVV1+dHZxLqR4aGhqysOnTp0/2NzF8+PDkzjvvTBobG5NC4usYAIii4K8BAVCcBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQACEGP4fsTzkpVTEaREAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities (first 5 samples):\n",
      "[[1.0230549e-18 7.0430810e-20 6.2314222e-13 3.5229641e-10 5.3375937e-21\n",
      "  8.9228779e-19 1.4081702e-22 1.0000000e+00 6.5325510e-17 4.9769276e-11]\n",
      " [8.9245589e-23 2.4616114e-15 9.9998730e-01 1.2728794e-05 1.6368996e-23\n",
      "  4.2283898e-13 1.0870879e-17 1.0555706e-17 2.1653588e-15 1.6906847e-12]\n",
      " [7.4819955e-17 9.9999988e-01 1.6939473e-09 1.9417246e-12 2.4095977e-12\n",
      "  6.2034003e-11 2.7658644e-09 1.6505093e-07 5.6863897e-10 4.7943611e-11]\n",
      " [9.9999803e-01 1.3376892e-12 2.0479758e-09 5.9814769e-19 2.9872658e-12\n",
      "  2.4912999e-12 7.8027590e-08 1.2086272e-12 2.4329228e-15 1.8979005e-06]\n",
      " [2.3542042e-11 1.8774957e-10 1.7305004e-07 1.6683199e-12 9.9999475e-01\n",
      "  5.8889305e-10 7.0282127e-08 1.5205998e-09 1.1045014e-09 4.8897332e-06]]\n",
      "\n",
      "Actual labels (first 5 samples):\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Predicted classes: [7 2 1 0 4]\n",
      "True classes: [7 2 1 0 4]\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "xtest = X_test[:5]\n",
    "ytest = Y_test[:5]\n",
    "\n",
    "for image in xtest:\n",
    "    for channel in image:\n",
    "        plt.imshow(channel, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "ypred = c(tensor(xtest))\n",
    "probs = ypred.softmax()\n",
    "\n",
    "print(\"Predicted probabilities (first 5 samples):\")\n",
    "print(probs.matrix[:5])\n",
    "print(\"Actual labels (first 5 samples):\")\n",
    "print(ytest[:5])\n",
    "\n",
    "# Check argmax accuracy\n",
    "pred_classes = np.argmax(probs.matrix, axis=1)\n",
    "true_classes = np.argmax(ytest, axis=1)\n",
    "print(f\"Predicted classes: {pred_classes}\")\n",
    "print(f\"True classes: {true_classes}\")\n",
    "print(f\"Accuracy: {(pred_classes == true_classes).mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "420ae0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = X_test[:10]\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d3a5cb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "for image in xtest:\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ndarray.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
