{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969b9f96",
   "metadata": {},
   "source": [
    "The goal of this notebook is to visualise individual activation maps and pools from various layer to get a sense of what's happening inside our model. We are essentially trying to white box the model. This is sort of like \"https://adamharley.com/nn_vis/cnn/2d.html\" but for CIFAR-10 dataset and we'll be focusing on visualising learnable weights rather than activations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b398a1",
   "metadata": {},
   "source": [
    "Firstly the imports!\n",
    "- The entire model runs in numpy python (CPU), but uses vectorised, efficient im2col and pooling operations. \n",
    "- Itertools is for specialised iteration for certain operation of tensor class\n",
    "- Matplotlib for visualization\n",
    "- We can use garbage collector which reduces the total memory usage to only 1GB for training. But, this drastically slows down training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5646f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550237f",
   "metadata": {},
   "source": [
    "This is the entire backbone of our model. \n",
    "- Firstly, we have the tensor class. It is a wrapper on numpy array that performs vector operations with child tracking and computational graph.\n",
    "- Secondly the Conv2d is the 2D convolutional layer with im2col operation. \n",
    "- The maxpool2D class is simply the pooling layer class.\n",
    "- FC (Fully Connected) class is the backbone of fully connected layer.\n",
    "\n",
    "Note: We dont have batch normalization yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae29521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor:\n",
    "    def __init__(self, fromArray=np.zeros((2,2)), _children = (), _operation = ''):\n",
    "        fromArray = fromArray if isinstance(fromArray, np.ndarray) else np.array(fromArray)\n",
    "        #assert len(fromArray.shape) == 2, \"Only 2D Tensors or Scalar to 2D Supported!\"\n",
    "        self.matrix = fromArray\n",
    "        #self.rows = fromArray.shape[0]\n",
    "        #self.columns = fromArray.shape[1]\n",
    "        self.shape = fromArray.shape\n",
    "        self._prev = set(_children)\n",
    "        self._operation = _operation\n",
    "        self._backward = lambda grad: None\n",
    "        self.grad = None\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor Values = {self.matrix}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def zeros(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = np.zeros(shape, dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.random.randn(*shape) * 0.1).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def he_init(cls, shape, fan_in, dtype=np.float32):\n",
    "        t = tensor()\n",
    "        std = np.sqrt(2.0 / fan_in)\n",
    "        t.matrix = (np.random.randn(*shape) * std).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def const(cls, shape, constant=1, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.full(shape, constant)).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    #Operations\n",
    "    def __add__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix + other.matrix\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            self.grad += self.return_unbroadcasted(grad) #Derivation in the notes. \n",
    "            other.grad += other.return_unbroadcasted(grad)\n",
    "        out = tensor(out_matrix, (self, other), '+')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self + (-1 * other)\n",
    "    \n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return other + (-1 * other)\n",
    "    \n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix * other.matrix\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            self.grad += self.return_unbroadcasted(grad) * other.matrix #Derivation in the notes. \n",
    "            other.grad += other.return_unbroadcasted(grad) * self.matrix\n",
    "\n",
    "        out = tensor(out_matrix, (self, other), '*')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self*other\n",
    "    \n",
    "    '''\n",
    "    batch multiplication might cause shape broadcasts.\n",
    "    eg. (3,2,2) @ (1,2,3) = (3,2,3)\n",
    "    this is similar to our element wise operations\n",
    "    thus we should be handling this the same way we did for elementwise operations\n",
    "    But, for now, we would be working in a controlled way (Even for CNNS)\n",
    "    and wouldn't need this handling. Or maybe we do!?\n",
    "    '''\n",
    "    def __matmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        assert other.shape[-2] == self.shape[-1], \"Dimension Unsupported for @\"\n",
    "        out_matrix = self.matrix @ other.matrix\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            self.grad += self.return_unbroadcasted(grad @ (other.matrix).swapaxes(-2,-1))#Derivation in the notes.\n",
    "            other.grad += self.return_unbroadcasted((self.matrix).swapaxes(-2,-1) @ grad) \n",
    "        out = tensor(out_matrix, (self, other), '@')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "\n",
    "    #I and thus we should learn at this point that to make our class compatible for ND tensors,\n",
    "    #We need the matrix multiplication and Transpose backward to change\n",
    "    #For higher dimensions, matmul = batch matmul where multiplication is done \n",
    "    #along each and every batches of 2D matrix. \n",
    "    #eg. If we have (2,3,3) shape tensor, it implies there are two batches of (3,3) matrices\n",
    "    #similarly, (2,3,3,2) shape = 2x3 batches of 3x2 matrices.\n",
    "    #matrix multiplication, (2,3,3) @ (2,3,2) = (2,3,2)\n",
    "    def swap_axes(self, axis1, axis2):\n",
    "        out_matrix = self.matrix.swapaxes(axis1, axis2)\n",
    "        \n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (grad).swapaxes(axis1,axis2) #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def transpose(self):\n",
    "        out_matrix = self.matrix.transpose()\n",
    "        \n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (grad).transpose() #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __rmatmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        return other @ self\n",
    "    \n",
    "    def __pow__(self, N):\n",
    "        assert isinstance(N, int | float), \"Can only power up by scalars!\"\n",
    "        out_matrix = self.matrix ** N\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += N * (self.matrix ** (N-1)) * self.return_unbroadcasted(grad)\n",
    "        \n",
    "        out = tensor(out_matrix, _children=(self, ), _operation=\"**\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self * (other**-1)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return other * (self**-1)\n",
    "    \n",
    "    def sum(self):\n",
    "        out_matrix = np.array(([[self.matrix.sum()]]))\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * grad\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='sum()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def mean(self):\n",
    "        N = np.prod(self.shape)\n",
    "        out_matrix = np.array(([[self.matrix.sum()/(N)]]))\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * grad / N\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='mean()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def ReLU(self):\n",
    "        out_matrix = np.maximum(0,self.matrix)\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (self.matrix > 0).astype(self.matrix.dtype) * grad\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"ReLU\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def reshape(self, shape):\n",
    "        assert isinstance(shape, tuple), f\"Can only reshape using shape tuples e.g. (3,3). Provided is {shape}\"\n",
    "        out_matrix = self.matrix.reshape(shape)\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"reshape()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def flatten(self):\n",
    "        out_matrix = self.matrix.reshape(-1,np.prod(self.shape[1:]))\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"flatten()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    #Helper Functions\n",
    "    #def shape(self):\n",
    "     #   return (self.rows, self.columns)\n",
    "\n",
    "    def return_unbroadcasted(self, grad):  \n",
    "        added_axis = []\n",
    "        stretched_axis = []\n",
    "        for index, (first_no, second_no) in enumerate(itertools.zip_longest(reversed(self.shape), reversed(grad.shape))):\n",
    "            if first_no is None:\n",
    "                added_axis.append(index)\n",
    "            elif (first_no == 1) and (second_no > 1):\n",
    "                stretched_axis.append(index)\n",
    "        ndim = len(grad.shape)\n",
    "        if stretched_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in stretched_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=True)\n",
    "        if added_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in added_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=False)\n",
    "        return grad\n",
    "\n",
    "    def checkOther(self, other):\n",
    "        if isinstance(other, int | float):\n",
    "            other = tensor.const(self.shape, other)\n",
    "        elif not isinstance(other, tensor):\n",
    "            other = tensor(other)\n",
    "        #assert other.shape == self.shape, \"Operand Tensor sizes dont match\"\n",
    "\n",
    "        return other\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.grad = None\n",
    "        \n",
    "    def backward(self):\n",
    "        self.grad = np.ones_like(self.matrix, dtype=np.float32)\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for current in reversed(topo):\n",
    "            current._backward(current.grad)\n",
    "\n",
    "            '''current._prev = set()\n",
    "            current._backward = lambda grad: None\n",
    "            '''\n",
    "\n",
    "    def cleanBackward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev: build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for t in reversed(topo):\n",
    "            t.grad = None\n",
    "            t._prev = ()\n",
    "            t._backward = lambda grad: None\n",
    "\n",
    "    def exp(self):\n",
    "        out_matrix = np.exp(self.matrix)\n",
    "        \n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out_matrix * grad  \n",
    "        \n",
    "        out = tensor(out_matrix, (self,), 'exp')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log(self, eps=1e-6):\n",
    "        clipped = np.clip(self.matrix, eps, None)  \n",
    "        out_matrix = np.log(clipped)\n",
    "        \n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (grad / clipped) \n",
    "        \n",
    "        out = tensor(out_matrix, (self,), 'log')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def softmax(self, axis=-1):\n",
    "        out_matrix = np.exp(self.matrix) / np.sum(np.exp(self.matrix), axis = axis, keepdims=True)\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out_matrix*(grad - np.sum(out_matrix * grad, axis = axis, keepdims=True))\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'softmax')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log_softmax(self, axis=-1, eps = 1e-6):\n",
    "        c = np.max(self.matrix, axis=axis, keepdims=True)\n",
    "\n",
    "        out_matrix = (self.matrix-c) - np.log(np.sum(np.exp(self.matrix-c), axis=axis, keepdims=True)+eps)\n",
    "        softmax = np.exp(self.matrix-c) / (np.sum(np.exp(self.matrix-c), axis = axis, keepdims=True)+eps)\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += grad - softmax * np.sum(grad, axis = axis, keepdims= True)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'log-softmax')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def padding(self, pad_h, pad_w):\n",
    "        np_padding = ((0, 0), (0, 0), (pad_h, pad_h), (pad_w, pad_w))\n",
    "        out_matrix = np.pad(self.matrix, np_padding, 'constant', constant_values=(0, ))\n",
    "\n",
    "        def _backward(grad):\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            h_end = -pad_h if pad_h > 0 else None\n",
    "            w_end = -pad_w if pad_w > 0 else None\n",
    "            self.grad += grad[:, :, pad_h:h_end, pad_w:w_end]\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='pad')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    __array_ufunc__ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f573ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=2, stride=1, padding = -1):\n",
    "        #self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "        fan_in = in_channels * kernel_size * kernel_size\n",
    "        self.kernel = tensor.he_init((out_channels, in_channels, kernel_size, kernel_size), fan_in)\n",
    "        self.bias = tensor.zeros((out_channels, ))\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.kernel, self.bias]\n",
    "\n",
    "    def __call__(self, X : tensor):\n",
    "\n",
    "        batch_size, channels, h, w = X.shape\n",
    "\n",
    "        if self.padding == -1: #same padding\n",
    "            pad_h = (self.stride *(h - 1) + self.kernel_size - h)//2\n",
    "            pad_w = (self.stride*(w - 1) + self.kernel_size - w)//2\n",
    "            X_padded = X.padding(pad_h, pad_w)\n",
    "\n",
    "        elif self.padding > 0:\n",
    "            X_padded = X.padding(self.padding, self.padding)\n",
    "\n",
    "        else:\n",
    "            X_padded = X\n",
    "\n",
    "        X_col, act_h, act_w = Conv2d.im2col(X_padded, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        K_col_shape = (self.out_channels, self.kernel_size*self.kernel_size*self.in_channels)\n",
    "        K_col = self.kernel.reshape(K_col_shape).transpose()\n",
    "        Y_col = X_col @ K_col + self.bias\n",
    "        Y = Y_col.reshape((batch_size, self.out_channels, act_h, act_w))\n",
    "        return Y\n",
    "        \n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size=2, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_h)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_w)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward(grad):\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            \n",
    "            grad_6D = grad.reshape(batch_size, act_h, act_w, channels, kernel_h, kernel_w)\n",
    "            for i in range(kernel_h):\n",
    "                for j in range(kernel_w):\n",
    "                    grad_slice = grad_6D[:, :, :, :, i, j]\n",
    "                    \n",
    "                    grad_slice_transposed = grad_slice.transpose(0, 3, 1, 2)\n",
    "                    X.grad[:, :, \n",
    "                        i : i + act_h * stride : stride, \n",
    "                        j : j + act_w * stride : stride\n",
    "                    ] += grad_slice_transposed\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out, act_h, act_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49fb6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maxpool2D:\n",
    "    def __init__(self, in_channels, pool_size = 2, stride = 1):\n",
    "        self.in_channels = in_channels\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def __call__(self, Y: tensor):\n",
    "\n",
    "        batch_number = Y.shape[0]\n",
    "        filters = Y.shape[1]\n",
    "        image_height = Y.shape[-2] #Rows\n",
    "        image_width = Y.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        pool_h = self.pool_size\n",
    "        pool_w = self.pool_size\n",
    "\n",
    "        pooled_h = (((image_height - pool_h)//self.stride) + 1) #height of activation\n",
    "        pooled_w = (((image_width - pool_w)//self.stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = Y.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            Y.matrix,\n",
    "                            shape=(batch_number, pooled_h, pooled_w, filters, pool_h, pool_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * self.stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * self.stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        intermediate_6D_transposed = intermediate_6D.transpose(0, 3, 1, 2, 4, 5)\n",
    "        intermediate_5D = intermediate_6D_transposed.reshape(batch_number, filters, pooled_h, pooled_w, pool_h * pool_w)\n",
    "\n",
    "        out_matrix = np.max(intermediate_5D, axis=-1)\n",
    "        IndexA_for5D = np.argmax(intermediate_5D, axis=-1)\n",
    "\n",
    "        def _backward(grad):\n",
    "            # Recover window position (i, j) from flat index in last dim\n",
    "            Y.grad = np.zeros_like(Y.matrix) if Y.grad is None else Y.grad\n",
    "            flat_idx = IndexA_for5D  # (B, F, pooled_h, pooled_w)\n",
    "            i = flat_idx // pool_w\n",
    "            j = flat_idx % pool_w\n",
    "\n",
    "            # Build grids for batch, filter, and pooled positions\n",
    "            b_grid = np.arange(batch_number).reshape(batch_number, 1, 1, 1)\n",
    "            f_grid = np.arange(filters).reshape(1, filters, 1, 1)\n",
    "            ph_grid = np.arange(pooled_h).reshape(1, 1, pooled_h, 1)\n",
    "            pw_grid = np.arange(pooled_w).reshape(1, 1, 1, pooled_w)\n",
    "\n",
    "            # Broadcast all to shape (B, F, pooled_h, pooled_w)\n",
    "            b_idx = np.broadcast_to(b_grid, flat_idx.shape)\n",
    "            f_idx = np.broadcast_to(f_grid, flat_idx.shape)\n",
    "            ph = np.broadcast_to(ph_grid, flat_idx.shape)\n",
    "            pw = np.broadcast_to(pw_grid, flat_idx.shape)\n",
    "\n",
    "            # Compute actual positions in Y where max values came from\n",
    "            h_idx = self.stride * ph + i\n",
    "            w_idx = self.stride * pw + j\n",
    "\n",
    "            # Accumulate gradients using 4D indexing\n",
    "            np.add.at(Y.grad, (b_idx.ravel(), f_idx.ravel(), h_idx.ravel(), w_idx.ravel()), grad.ravel())\n",
    "\n",
    "        out = tensor(out_matrix, _children=(Y, ), _operation=\"maxpool\")\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc4244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \n",
    "        self.bias = tensor.zeros((1, out_features))\n",
    "        self.weights = tensor.he_init((in_features, out_features), in_features)\n",
    "        #self.weights = tensor.random((out_features, in_features))\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.bias]\n",
    "\n",
    "    def __call__(self, X:tensor):\n",
    "        return (X @ self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f920ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, in_channels, layers, kernels_in_layers, kernels_shape, conv_strides, pool_shape, pool_strides, FCL_weights):\n",
    "\n",
    "        self.in_channels = (in_channels, ) + kernels_in_layers\n",
    "        self.FCL_weights = FCL_weights\n",
    "        self.layers = layers\n",
    "        #self.conv_layers = [Conv2d(in_channels[layer], kernels_in_layers[layer], kernels_shape[layer], conv_strides[layer]) for layer in range(layers)]\n",
    "        self.conv_layers = [Conv2d(self.in_channels[layer], kernels_in_layers[layer], kernels_shape[layer], conv_strides[layer]) for layer in range(layers)]\n",
    "        self.pool_layers = [maxpool2D(kernels_in_layers[layer], pool_shape[layer], pool_strides[layer]) for layer in range(layers)]\n",
    "        self.FC_layers = [None for _ in range(layers+1)]\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in range(self.layers):\n",
    "            params.extend(self.conv_layers[layer].parameters())\n",
    "            params.extend(self.FC_layers[layer].parameters())\n",
    "        #params.extend(self.FC_layers[layer+1].parameters())\n",
    "        return params\n",
    "\n",
    "    def __call__(self, X:tensor):\n",
    "        b = X\n",
    "        for layer in range(self.layers):\n",
    "            b = self.pool_layers[layer](self.conv_layers[layer](b).ReLU())\n",
    "        \n",
    "        out:tensor = b.reshape((X.shape[0], -1))\n",
    "        if self.FC_layers[0] is None:\n",
    "            self.FC_layers[0] = FC(out.shape[1], self.FCL_weights[0])\n",
    "\n",
    "        for layer in range(self.layers):\n",
    "            if self.FC_layers[layer] is None:\n",
    "                self.FC_layers[layer] = FC(self.FCL_weights[layer-1], self.FCL_weights[layer])\n",
    "\n",
    "            out = self.FC_layers[layer](out)\n",
    "            \n",
    "        #out = c.transpose()\n",
    "        return out\n",
    "\n",
    "    def save_model(self, filename=\"cifar10_model.npz\"):\n",
    "        weights_dict = {}\n",
    "        for i, param in enumerate(self.parameters()):\n",
    "            weights_dict[f'param_{i}'] = param.matrix\n",
    "        \n",
    "        np.savez(filename, **weights_dict)\n",
    "        print(f\"Model saved to {filename}\")\n",
    "\n",
    "\n",
    "    def load_model(self, filename=\"cifar10_model_best.npz\"):\n",
    "        loaded_data = np.load(filename)\n",
    "        for i, param in enumerate(self.parameters()):\n",
    "            if param.shape == loaded_data[f'param_{i}'].shape:\n",
    "                param.matrix= loaded_data[f'param_{i}']\n",
    "            else:\n",
    "                raise ValueError(f\"Shape Mismatch at index {i}: Model expects {param.shape}, loaded {loaded_data[f'param_{i}'].shape}\")\n",
    "\n",
    "    @classmethod\n",
    "    def cross_entropy_loss(cls, ypredicted: tensor, ytrue, batch_size):\n",
    "        ytrue =  tensor(ytrue) if not isinstance(ytrue, tensor) else ytrue\n",
    "        cross_entropy = ypredicted.log_softmax(axis=-1)\n",
    "        loss = ((-1 * ytrue * cross_entropy).sum())/batch_size\n",
    "        #loss = ((ytrue * cross_entropy).sum())\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 10, lr = 0.001, batch_size = 32):\n",
    "        lossT = []\n",
    "        save_count = 0\n",
    "        ep = 0\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            n_batches = 0\n",
    "            perm = np.random.permutation(len(X_train))\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                idx = perm[i:i+batch_size]\n",
    "                xb = tensor(X_train[idx])             \n",
    "                yb = tensor(y_train[idx]) \n",
    "\n",
    "                y_predicted = self(xb)\n",
    "\n",
    "                ce_loss = CNN.cross_entropy_loss(y_predicted, yb, len(idx))\n",
    "\n",
    "                ce_loss.backward()\n",
    "\n",
    "                for param in self.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        #grad_clipped = np.clip(param.grad, -1.0, 1.0)\n",
    "                        #param.matrix -= lr * grad_clipped\n",
    "                        param.matrix -= lr * param.grad\n",
    "                        param.grad = None\n",
    "\n",
    "                \n",
    "                n_batches += 1\n",
    "                epoch_loss += float(ce_loss.matrix.item())\n",
    "\n",
    "                # Clean up\n",
    "                xb.cleanBackward()\n",
    "                yb.cleanBackward()\n",
    "                ce_loss.cleanBackward()\n",
    "                y_predicted.cleanBackward()\n",
    "                del xb, yb, y_predicted, ce_loss\n",
    "                #if n_batches >= 200:\n",
    "                #    gc.collect()\n",
    "\n",
    "            ep+=1\n",
    "            if ep >= 10:\n",
    "                save_count += 1\n",
    "                filename=f\"cifar10_model_{save_count}.npz\"\n",
    "                self.save_model(filename)\n",
    "                ep = 0\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
    "            lossT.append((epoch, avg_loss))\n",
    "\n",
    "        return lossT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2f1a6",
   "metadata": {},
   "source": [
    "Now let's prepare the CIFAR-10 dataset.\n",
    "1. Load dataset\n",
    "2. Normalise training images\n",
    "3. Encode classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f33850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawanadhikari/Documents/Roadmap/MachineLearningMaths/.venv/lib/python3.14/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "/Users/pawanadhikari/Documents/Roadmap/MachineLearningMaths/.venv/lib/python3.14/site-packages/keras/src/datasets/cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.transpose(0, 3, 1, 2).astype(np.float32) / 255.0  \n",
    "X_test = X_test.transpose(0, 3, 1, 2).astype(np.float32) / 255.0\n",
    "Y_train = np.zeros((y_train.size, 10))\n",
    "Y_train[np.arange(y_train.size), y_train.flatten()] = 1\n",
    "Y_test = np.zeros((y_test.size, 10))\n",
    "Y_test[np.arange(y_test.size), y_test.flatten()] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cd0b5",
   "metadata": {},
   "source": [
    "Shapes for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e11f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(50000, 10)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b8ecf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing first 4 images.\n",
    "'''\n",
    "for image in X_test[:4]:\n",
    "    image = image.transpose(1,2,0)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "'''\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(4, 4))\n",
    "ax[0,0].imshow(X_test[0].transpose(1,2,0))\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].imshow(X_test[1].transpose(1,2,0))\n",
    "ax[0,1].axis('off')\n",
    "ax[1,0].imshow(X_test[2].transpose(1,2,0))\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].imshow(X_test[3].transpose(1,2,0))\n",
    "ax[1,1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfd80e",
   "metadata": {},
   "source": [
    "And let's see the outputs now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a532f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [8],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef9d5e",
   "metadata": {},
   "source": [
    "After Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "092d732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce2124",
   "metadata": {},
   "source": [
    "We can delete the non encoded Y values to free some memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b554734",
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_test, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa916e87",
   "metadata": {},
   "source": [
    "Now, Let us train a simple CNN for this dataset. \n",
    "\n",
    "Note: We already have few trained models in this directory which we can directly load. Only try training if you want to. You can play around with the model architecture. The key components we have for CNN are as follows:\n",
    "1. Conv2D layer with vectorised im2col and col2m operations. Does same padding by default, but can be changed in Conv2D class or CNN class during invocation. (We can modify CNN class to send padding size as argument.). Strides and kernel size can be configured during model initialisation.\n",
    "2. MaxPool layer with strides and pool size.\n",
    "3. Fully Connected Layer with configurable output channel weights.\n",
    "4. ReLU after Conv2D (modify at CNN class.)\n",
    "5. Log_Softmax operation at the end.\n",
    "6. Cross Entropy Loss as class method in CNN class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a10b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.940271\n"
     ]
    }
   ],
   "source": [
    "model = CNN(\n",
    "    in_channels=3,\n",
    "    layers=2,\n",
    "    kernels_in_layers= (16, 32, ),\n",
    "    kernels_shape= (3, 3, ),\n",
    "    conv_strides= (1, 1, ),\n",
    "    pool_shape= (2, 2, ),\n",
    "    pool_strides= (2, 2, ), \n",
    "    FCL_weights= (128, 10, ) \n",
    ")\n",
    "\n",
    "#Since training is CPU accelerated, expect slow training time.\n",
    "#We might want to use slices of training data if we dont want to wait for long.\n",
    "loss = model.fit(X_train, Y_train, epochs=100, lr=0.05, batch_size=32)\n",
    "\n",
    "#Plot Train Loss vs Epochs graph.\n",
    "epochs, losses = zip(*loss)\n",
    "plt.plot(epochs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bccea",
   "metadata": {},
   "source": [
    "Again, we can clear up unwanted lists to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del  model, loss, epochs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del loss, epochs, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737759bd",
   "metadata": {},
   "source": [
    "This checks the accuracy on the whole test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee32dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities (first 5 samples):\n",
      "[[2.38185006e-04 3.56888468e-03 4.10292391e-03 ... 1.00570533e-03\n",
      "  2.92098951e-02 5.79489279e-04]\n",
      " [5.35541773e-02 7.96142399e-01 1.13698626e-07 ... 2.50790499e-09\n",
      "  1.50177211e-01 1.24296901e-04]\n",
      " [1.36488900e-01 1.12551570e-01 2.18020810e-04 ... 2.85699731e-04\n",
      "  7.36620367e-01 1.15130721e-02]\n",
      " ...\n",
      " [4.03757658e-05 2.42100024e-04 2.55862355e-01 ... 4.05984223e-02\n",
      "  2.51121761e-04 3.06155416e-05]\n",
      " [4.35737567e-03 8.98784101e-01 4.61420463e-03 ... 1.26492378e-04\n",
      "  4.92282677e-03 8.78328632e-04]\n",
      " [2.39426474e-04 2.66371615e-04 1.43356612e-02 ... 5.77097893e-01\n",
      "  9.35482676e-05 5.55334191e-05]]\n",
      "Actual labels (first 5 samples):\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Predicted classes: [5 1 8 0 4 6 1 2 4 1]\n",
      "True classes: [3 8 8 0 6 6 1 6 3 1]\n",
      "Accuracy: 55.8%\n"
     ]
    }
   ],
   "source": [
    "xtest = X_test\n",
    "ytest = Y_test\n",
    "\n",
    "\"\"\"\n",
    "for image in xtest:\n",
    "    plt.imshow(image.transpose(1,2,0))\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "ypred = model(tensor(xtest))\n",
    "probs = ypred.softmax()\n",
    "\n",
    "print(\"Predicted probabilities (first 5 samples):\")\n",
    "print(probs.matrix)\n",
    "print(\"Actual labels (first 5 samples):\")\n",
    "print(ytest)\n",
    "\n",
    "# Check argmax accuracy\n",
    "pred_classes = np.argmax(probs.matrix, axis=1)\n",
    "true_classes = np.argmax(ytest, axis=1)\n",
    "print(f\"Predicted classes: {pred_classes[:10]}\")\n",
    "print(f\"True classes: {true_classes[:10]}\")\n",
    "print(f\"Accuracy: {(pred_classes == true_classes).mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396956b",
   "metadata": {},
   "source": [
    "Model Loading from preexisting model files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75b4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(\n",
    "    in_channels=3,\n",
    "    layers=2,\n",
    "    kernels_in_layers= (16, 32, ),\n",
    "    kernels_shape= (3, 3, ),\n",
    "    conv_strides= (1, 1, ),\n",
    "    pool_shape= (2, 2, ),\n",
    "    pool_strides= (2, 2, ),\n",
    "    FCL_weights= (128, 10)\n",
    ")\n",
    "\n",
    "model(tensor(X_test[:1]))\n",
    "\n",
    "model.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59788b41",
   "metadata": {},
   "source": [
    "Finally the Visualisation of filters!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer shape: (16, 3, 3, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "params = list(model.parameters())\n",
    "first_layer_weights = params[0].matrix \n",
    "\n",
    "w = first_layer_weights\n",
    "w_min, w_max = w.min(), w.max()\n",
    "w = (w - w_min) / (w_max - w_min)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "num_filters = min(16, w.shape[0])\n",
    "\n",
    "for i in range(num_filters):\n",
    "    # Extract filter\n",
    "    f = w[i]\n",
    "    \n",
    "    if f.shape[0] == 3: \n",
    "        f = f.transpose(1, 2, 0)\n",
    "        \n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(f)\n",
    "    ax.set_title(f\"Kernel {i}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15067359",
   "metadata": {},
   "source": [
    "These patterns aren't random! Some are edge detectors, some are colour detectors, etc. This is the very first layer of weights in our CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
