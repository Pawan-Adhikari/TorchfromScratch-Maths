{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04512a4f",
   "metadata": {},
   "source": [
    "We will be implementing a CNN from scratch heere using just Numpy. Here, I will keep the entire evolution of code until we get a final, polished CNN architecture. This way, we can understand the problems and implementations in a chronological way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d020df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec192cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the fundamentals of CNN:\n",
    "\n",
    "#Take W size Input Image.\n",
    "#Use a filter of size K.\n",
    "#Return output of size W-k+1 (No Padding, No Stride).\n",
    "#We will use and understand Padding & Stride as we progress into bottlenecks and more complex problems. \n",
    "#The main task here is to develop algorithm to convolute the filter through the image.\n",
    "\n",
    "class con2d:\n",
    "    def __init__(self, w, k):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.filter = np.random.rand(k,k)\n",
    "        self.bias = random.uniform(-1,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sum = 0\n",
    "        Y = np.zeros((self.W + 1 - self.K, self.W + 1 - self.K))\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        sum += patch[a,b] * self.filter[a,b]\n",
    "                #sum += self.bias\n",
    "                #sum = np.tanh(sum)\n",
    "                Y[i,j] = sum\n",
    "                sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c469f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m input_image = np.array([\n\u001b[32m      2\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m      3\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m      7\u001b[39m ])\n\u001b[32m      9\u001b[39m kernel = np.array([\n\u001b[32m     10\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m],\n\u001b[32m     11\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m],\n\u001b[32m     12\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m]\n\u001b[32m     13\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m myCNN = \u001b[43mcon2d\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m myCNN.filter = kernel\n\u001b[32m     17\u001b[39m myCNN.forward(input_image)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mcon2d.__init__\u001b[39m\u001b[34m(self, w, k)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.K = k\n\u001b[32m     13\u001b[39m \u001b[38;5;28mself\u001b[39m.filter = np.random.rand(k,k)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mself\u001b[39m.bias = \u001b[43mrandom\u001b[49m.uniform(-\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "input_image = np.array([\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "myCNN = con2d(5,3)\n",
    "myCNN.filter = kernel\n",
    "myCNN.forward(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e7c91",
   "metadata": {},
   "source": [
    "This was an extremely inefficient implementation but we did get correct outcome. For now lets focus on the fact that CNNs work on rgb data which has 3 channels. But our code assumes an image as a flat 2D surface. We have to add depth/channel to our input matrix and thus our kernel. But importantly, our output matrix/activation map must remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class con2d:\n",
    "    def __init__(self, w, k, c):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.C = c #Channel\n",
    "        self.filter = np.random.rand(k,k,c)\n",
    "        self.bias = random.uniform(-1,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sum = 0\n",
    "        Y = np.zeros((self.W + 1 - self.K, self.W + 1 - self.K))\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K, :]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        for c in range(self.C):\n",
    "                            sum += patch[a,b,c] * self.filter[a,b,c]\n",
    "                #sum += self.bias\n",
    "                #sum = np.tanh(sum)\n",
    "                Y[i,j] = sum\n",
    "                sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c68f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9., -9.],\n",
       "       [-9., -9.]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vol = np.zeros((4, 4, 2))\n",
    "input_vol[:, :, 0] = 1\n",
    "input_vol[:, :, 1] = 2\n",
    "\n",
    "kernel = np.zeros((3, 3, 2))\n",
    "kernel[:, :, 0] = 1\n",
    "kernel[:, :, 1] = -1\n",
    "\n",
    "myCNN = con2d(4,3,2)\n",
    "myCNN.filter = kernel\n",
    "myCNN.forward(input_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e517e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make this complete, lets uncomment bias application and let's try to have more than one filters.\n",
    "class con2d:\n",
    "    def __init__(self, w, k, c, n):\n",
    "        self.W = w\n",
    "        self.K = k\n",
    "        self.C = c #Channels\n",
    "        self.Cn = n #Number of filters\n",
    "        self.filters = [np.random.rand(k,k,c) for _ in range(n)]\n",
    "        self.bias = [random.uniform(-1,1) for _ in range(n)]\n",
    "\n",
    "    def forward(self, X):\n",
    "        sums = np.zeros(self.Cn)\n",
    "        Y = [np.zeros((self.W + 1 - self.K, self.W + 1 - self.K)) for _ in range(self.Cn)]\n",
    "        for i in range(self.W + 1 - self.K):\n",
    "            for j in range(self.W + 1 - self.K):\n",
    "                patch = X[i:i+self.K, j:j+self.K, :]\n",
    "                for a in range(self.K):\n",
    "                    for b in range(self.K):\n",
    "                        for c in range(self.C):\n",
    "                            for index, filter in enumerate(self.filters):\n",
    "                                sums[index] += patch[a,b,c] * filter[a,b,c]\n",
    "                for idx, sum in enumerate(sums):\n",
    "                    sum += self.bias[idx]\n",
    "                    #sum = np.tanh(sum)\n",
    "                    Y[idx][i,j] = sum\n",
    "                    sum = 0\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaaee71",
   "metadata": {},
   "source": [
    "But these nested loops are extremely inefficient. We have to adress this. Modern libraries like pytorch and tensorflow use a standard practice called \"im2col\" where the entire image is stretched into a single vector arranged by the filter size. One way is to then also dilate our filter adding zeros in between such that a single matrix multiplication will simulate the filter being slid over the image. \n",
    "\n",
    "This however, would be inefficient. Why? We aren't using multiple nested loops which significantly improve performance. But, we are doing unecessarily large matrix multiplication involving 0 elements.\n",
    "\n",
    "\n",
    "Best and SoTA practice is to flatten the image locally. I.e. we flatten only the receptive field of the kernel eg. 3x3x3, and then matmul it with our flattened kernel(3x3x3). This results in matmul between a 1x27 image and 27x1 kernel, resulting in a single scalar value. This scalar corresponds to a single pixel of the activation map after being added to the scalar bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a6085",
   "metadata": {},
   "source": [
    "Let's take an example. Start from inputs of dimension 16x3x32x32 where 16 is the batch size, 3 is the number of channels and 32x32 is the image size. So we have 16 rgb images of 32x32 resolution as input each batch. Consider a kernel size of 128x3x2x2 where 128 is the number of kernels, 3 represents rgb and 3x3 is the kernel size. \n",
    "\n",
    "How does im2col work in this case? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32d88c",
   "metadata": {},
   "source": [
    "Firstly, calculate the receptive field size or the output field size.\n",
    "\n",
    "O = ((I - K + 2P)/S) + 1\n",
    "\n",
    "This is the standard formula where:\n",
    "- I : Input image size (eg. 32x32)\n",
    "- K : Kernel size (eg. 3x3)\n",
    "- P : Zero Padding size (eg. 0 or 1 if we want O to be 32 = I)\n",
    "- S : Stride (eg. 1)\n",
    "- O : Output Activation size\n",
    "\n",
    "Here, \n",
    "\n",
    "O = ((32-3+0)/1) + 1 = 30\n",
    "\n",
    "So we get activation map of 30x30 per kernel.\n",
    "\n",
    "If we want the activation map to be same size of that of input, we have to introduce padding: Specifically same padding. \n",
    "\n",
    "In our example, same padding requires padding = 1\n",
    "\n",
    "Therefore we get, O = ((32-3+2)/1) + 1 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab4571",
   "metadata": {},
   "source": [
    "For now, let us assume the initial case with no Padding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60637dec",
   "metadata": {},
   "source": [
    "## Im2col Transformation Step-by-Step\n",
    "\n",
    "### Given:\n",
    "- Input: (16, 3, 32, 32) - 16 batches, 3 channels, 32×32 images\n",
    "- Kernels: (128, 3, 3, 3) - 128 output channels/kernels/activation maps, 3 input channels, 3×3 spatial\n",
    "- Output size: O = ((32 - 3 + 0) / 1) + 1 = **30×30**\n",
    "\n",
    "### Step 1: Extract All Receptive Fields\n",
    "\n",
    "For each image in the batch:\n",
    "- Each receptive field: 3×3×3 = **27 elements**\n",
    "- Number of positions: 30×30 = **900 positions**\n",
    "- Total number of flattened matrices that represent all positions: **(900, 27)** (But this flatenning requires special handling so that we differentiate from 27 contigious memory of the image, and 27 neighbouring pixels that constitute a receptive field.)\n",
    "\n",
    "For the entire batch (16 images):\n",
    "- We stack all of them vertically (16 × 900, 27) = **(14,400, 27)**\n",
    "\n",
    "### Step 2: Flatten All 128 Kernels\n",
    "\n",
    "- Each kernel: 3×3×3 = 27 elements\n",
    "- Kernels shape: **(27, 128)**\n",
    "\n",
    "Why? 27 weights for each 128 kernels. \n",
    "\n",
    "### Step 3: Giant MatMul\n",
    "\n",
    "(14,400, 27) @ (27, 128) = **(14,400, 128)**\n",
    "\n",
    "### Step 4: Reshape and Add Bias\n",
    "\n",
    "Reshape (14,400, 128) → (16, 128, 30, 30)\n",
    "Add bias (128,) → broadcasts to (16, 128, 30, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f627a",
   "metadata": {},
   "source": [
    "## So lets draw some conclusions first!\n",
    "\n",
    "1. We need special type of matrix flatenning such that all pixels of local receptive fields(3x3x3 = 27) are in one dimension(x, 27) and all such local receptive fields(30x30 = 900) are in another, batch dimension(900, x) which represents the number of such possible receptive fields. This corresponds to number of pixels in activation map. Finally we need to consider all the receptive fields of all images in the batch. This doesnot create new dimension (not, eg. 16x900x27), but we stack all the receptive fields of all the images vertically. (i.e 900x16 = 14,400). Therefore we get final flatenned 2D matrix of shape = 14400, 27.\n",
    "\n",
    "    ## Therefore:\n",
    "    Local receptive field pixels must be arranged non contigiously relative to the image.\n",
    "\n",
    "    eg.\n",
    "\n",
    "    11  12  13\n",
    "\n",
    "    21  22  23\n",
    "\n",
    "    31  32  33\n",
    "\n",
    "    should not be flattened as: \n",
    "\n",
    "    [11, 12, 13, 14],\n",
    "        \n",
    "    [13, 21, 22, 23], \n",
    "\n",
    "\n",
    "    [22, 23, 31, 32], \n",
    "\n",
    "    [31, 32, 33, 11] \n",
    "\n",
    "    Shape(4x4)\n",
    "\n",
    "    or,\n",
    "\n",
    "    [1,2,3,4,5,6,7,8,9] : Shape (9)\n",
    "\n",
    "    But as:\n",
    "    \n",
    "    [11, 12, 21, 22],\n",
    "\n",
    "    [12, 13, 22, 23],\n",
    "\n",
    "    [21, 22, 23, 31],\n",
    "\n",
    "    [22, 23, 32, 33]\n",
    "\n",
    "    Shape(4x4)\n",
    "\n",
    "\n",
    "2. To define our convolution layer, we need to know some parameters:\n",
    "- Depth/No. of Channels of Kernel which corresponds to input channels(in_channels)\n",
    "- Depth/No. of Channels of Activation/Output which corresponds to number of kernels (out_channels)\n",
    "- Kernel size (kernel_size eg.(2) -> 2x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor:\n",
    "    def __init__(self, fromArray=np.zeros((2,2)), _children = (), _operation = ''):\n",
    "        fromArray = fromArray if isinstance(fromArray, np.ndarray) else np.array(fromArray)\n",
    "        #assert len(fromArray.shape) == 2, \"Only 2D Tensors or Scalar to 2D Supported!\"\n",
    "        self.matrix = fromArray\n",
    "        #self.rows = fromArray.shape[0]\n",
    "        #self.columns = fromArray.shape[1]\n",
    "        self.shape = fromArray.shape\n",
    "        self._prev = set(_children)\n",
    "        self._operation = _operation\n",
    "        self._backward = lambda : None\n",
    "        self.grad = None\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor Values = {self.matrix}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def zeros(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = np.zeros(shape, dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls, shape, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.random.randn(*shape) * 0.1).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def he_init(cls, shape, fan_in, dtype=np.float32):\n",
    "        t = tensor()\n",
    "        std = np.sqrt(2.0 / fan_in)\n",
    "        t.matrix = (np.random.randn(*shape) * std).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    @classmethod\n",
    "    def const(cls, shape, constant=1, dtype = np.float32):\n",
    "        t = tensor()\n",
    "        t.matrix = (np.full(shape, constant)).astype(dtype=dtype)\n",
    "        t.shape = shape\n",
    "        return t\n",
    "    \n",
    "    #Operations\n",
    "    def __add__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix + other.matrix\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            out2 = other.return_unbroadcasted(out)\n",
    "            self.grad += out1 #Derivation in the notes. \n",
    "            other.grad += out2\n",
    "        out = tensor(out_matrix, (self, other), '+')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self + (-1 * other)\n",
    "    \n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return other + (-1 * other)\n",
    "    \n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        out_matrix = self.matrix * other.matrix\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(out.grad) if other.grad is None else other.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            out2 = other.return_unbroadcasted(out)\n",
    "            self.grad += out1* other.matrix #Derivation in the notes. \n",
    "            other.grad += out2 * self.matrix\n",
    "\n",
    "        out = tensor(out_matrix, (self, other), '*')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self*other\n",
    "    \n",
    "    '''\n",
    "    batch multiplication might cause shape broadcasts.\n",
    "    eg. (3,2,2) @ (1,2,3) = (3,2,3)\n",
    "    this is similar to our element wise operations\n",
    "    thus we should be handling this the same way we did for elementwise operations\n",
    "    But, for now, we would be working in a controlled way (Even for CNNS)\n",
    "    and wouldn't need this handling.\n",
    "    '''\n",
    "    def __matmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        assert other.shape[-2] == self.shape[-1], \"Dimension Unsupported for @\"\n",
    "        out_matrix = self.matrix @ other.matrix\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            other.grad = np.zeros_like(other.matrix) if other.grad is None else other.grad\n",
    "            self.grad += out.grad @ (other.matrix).swapaxes(-2,-1)#Derivation in the notes.\n",
    "            other.grad += (self.matrix).swapaxes(-2,-1) @ out.grad \n",
    "        out = tensor(out_matrix, (self, other), '@')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "\n",
    "    #I and thus we should learn at this point that to make our class compatible for ND tensors,\n",
    "    #We need the matrix multiplication and Transpose backward to change\n",
    "    #For higher dimensions, matmul = batch matmul where multiplication is done \n",
    "    #along each and every batches of 2D matrix. \n",
    "    #eg. If we have (2,3,3) shape tensor, it implies there are two batches of (3,3) matrices\n",
    "    #similarly, (2,3,3,2) shape = 2x3 batches of 3x2 matrices.\n",
    "    #matrix multiplication, (2,3,3) @ (2,3,2) = (2,3,2)\n",
    "    def swap_axes(self, axis1, axis2):\n",
    "        out_matrix = self.matrix.swapaxes(axis1, axis2)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad.swapaxes(axis1,axis2)) if self.grad is None else self.grad\n",
    "            self.grad += (out.grad).swapaxes(axis1,axis2) #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def transpose(self):\n",
    "        out_matrix = self.matrix.transpose()\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(out.grad.transpose()) if self.grad is None else self.grad\n",
    "            self.grad += (out.grad).transpose() #Not in note, but can be derived similarly.\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'T')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __rmatmul__(self, other):\n",
    "        other = other if isinstance(other, tensor) else tensor(other)\n",
    "        return other @ self\n",
    "    \n",
    "    def __pow__(self, N):\n",
    "        assert isinstance(N, int | float), \"Can only power up by scalars!\"\n",
    "        out_matrix = self.matrix ** N\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            out1 = self.return_unbroadcasted(out)\n",
    "            self.grad += N * (self.matrix ** (N-1)) * out1\n",
    "        \n",
    "        out = tensor(out_matrix, _children=(self, ), _operation=\"**\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        other = self.checkOther(other)\n",
    "        return self * (other**-1)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return other * (self**-1)\n",
    "    \n",
    "    def sum(self):\n",
    "        out_matrix = np.array(([[self.matrix.sum()]]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * out.grad\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='sum()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def mean(self):\n",
    "        N = np.prod(self.shape)\n",
    "        out_matrix = np.array(([[self.matrix.sum()/(N)]]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += np.ones_like(self.matrix) * out.grad / N\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='mean()')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def ReLU(self):\n",
    "        out_matrix = np.maximum(0,self.matrix)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (self.matrix > 0).astype(self.matrix.dtype) * out.grad\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"ReLU\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def reshape(self, shape):\n",
    "        assert isinstance(shape, tuple), f\"Can only reshape using shape tuples e.g. (3,3). Provided is {shape}\"\n",
    "        out_matrix = self.matrix.reshape(shape)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"reshape()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def flatten(self):\n",
    "        out_matrix = self.matrix.reshape(-1,np.prod(self.shape[1:]))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad.reshape(self.shape)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), \"flatten()\")\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    #Helper Functions\n",
    "    #def shape(self):\n",
    "     #   return (self.rows, self.columns)\n",
    "\n",
    "    def return_unbroadcasted(self, out):  \n",
    "        added_axis = []\n",
    "        stretched_axis = []\n",
    "        for index, (first_no, second_no) in enumerate(itertools.zip_longest(reversed(self.shape), reversed(out.shape))):\n",
    "            if first_no is None:\n",
    "                added_axis.append(index)\n",
    "            elif (first_no == 1) and (second_no > 1):\n",
    "                stretched_axis.append(index)\n",
    "        grad = out.grad\n",
    "        ndim = len(out.shape)\n",
    "        if stretched_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in stretched_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=True)\n",
    "        if added_axis:\n",
    "            original_axes = tuple(ndim - 1 - i for i in added_axis)\n",
    "            grad = np.sum(grad, axis=original_axes, keepdims=False)\n",
    "        return grad\n",
    "\n",
    "    def checkOther(self, other):\n",
    "        if isinstance(other, int | float):\n",
    "            other = tensor.const(self.shape, other)\n",
    "        elif not isinstance(other, tensor):\n",
    "            other = tensor(other)\n",
    "        #assert other.shape == self.shape, \"Operand Tensor sizes dont match\"\n",
    "\n",
    "        return other\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.grad = None\n",
    "        \n",
    "    def backward(self):\n",
    "        self.grad = np.ones_like(self.matrix, dtype=float)\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for current in reversed(topo):\n",
    "\n",
    "            current._backward()\n",
    "\n",
    "    def cleanBackward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev: build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for t in topo:\n",
    "            t._prev = ()\n",
    "            t._backward = lambda: None\n",
    "\n",
    "    def exp(self):\n",
    "        out_matrix = np.exp(self.matrix)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out_matrix * out.grad  \n",
    "        \n",
    "        out = tensor(out_matrix, (self,), 'exp')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log(self, eps=1e-8):\n",
    "        clipped = np.clip(self.matrix, eps, None)  \n",
    "        out_matrix = np.log(clipped)\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += (1.0 / clipped) * out.grad \n",
    "        \n",
    "        out = tensor(out_matrix, (self,), 'log')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def softmax(self, axis=-1):\n",
    "        out_matrix = np.exp(self.matrix) / np.sum(np.exp(self.matrix), axis = axis, keepdims=True)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out_matrix*(out.grad - np.sum(out_matrix * out.grad, axis = axis, keepdims=True))\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'softmax')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log_softmax(self, axis=-1):\n",
    "        out_matrix = self.matrix - np.log(np.sum(np.exp(self.matrix), axis=axis, keepdims=True))\n",
    "        softmax = np.exp(self.matrix) / np.sum(np.exp(self.matrix), axis = axis, keepdims=True)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            self.grad += out.grad - softmax * np.sum(out.grad, axis = axis, keepdims= True)\n",
    "\n",
    "        out = tensor(out_matrix, (self, ), 'log-softmax')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def padding(self, pad_h, pad_w):\n",
    "        np_padding = ((0, 0), (0, 0), (pad_h, pad_h), (pad_w, pad_w))\n",
    "        out_matrix = np.pad(self.matrix, np_padding, 'constant', constant_values=(0, ))\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = np.zeros_like(self.matrix) if self.grad is None else self.grad\n",
    "            h_end = -pad_h if pad_h > 0 else None\n",
    "            w_end = -pad_w if pad_w > 0 else None\n",
    "            self.grad += out.grad[:, :, pad_h:h_end, pad_w:w_end]\n",
    "\n",
    "        out = tensor(out_matrix, _children=(self, ), _operation='pad')\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    __array_ufunc__ = None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size, stride):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            grad_6D = np.reshape(out.grad, shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w,))\n",
    "\n",
    "            #For each element in this 6D tensor, having 6D index, we have to calculate the coresponding 4D index.\n",
    "            #The formula has been conceptually derived in the notes.\n",
    "            #Here, we first generate all the indices of the 6D tensor and store each index dimension in separate list\n",
    "            #Then using the derived formula, we batch convert the 6D indices to 4D indices.\n",
    "\n",
    "            batch = np.arange(batch_size).reshape(batch_size,1,1,1,1,1)\n",
    "            field_h = np.arange(act_h).reshape(1,act_h,1,1,1,1)\n",
    "            field_w = np.arange(act_w).reshape(1,1,act_w,1,1,1)\n",
    "            channel = np.arange(channels).reshape(1,1,1,channels,1,1)\n",
    "            k_h = np.arange(kernel_h).reshape(1,1,1,1,kernel_h,1)\n",
    "            k_w = np.arange(kernel_w).reshape(1,1,1,1,1,kernel_w)\n",
    "\n",
    "            x = stride * field_h + k_h\n",
    "            y = stride * field_w + k_w\n",
    "\n",
    "            np.add.at(X.grad, (batch, channel, x, y), grad_6D)\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  (16, 3, 5, 5)\n",
      "Output Shape:  (64, 27)\n"
     ]
    }
   ],
   "source": [
    "batch = tensor(np.random.randn(16, 3, 5, 5).astype(float))\n",
    "\n",
    "print(\"Input Shape: \", batch.shape)\n",
    "\n",
    "im2col = Conv2d.im2col(batch, 3, 2)\n",
    "\n",
    "print(\"Output Shape: \", im2col.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a5042",
   "metadata": {},
   "source": [
    "This was a valid approach. Elegant and shows the direct use of formula. But, we have an even more efficient approach. It involves slicing. In this method, instead of creating large index array which requires both time and memory, we can call 2 simple for loops to loop over the kernel sizes and slice the out.grad array for each position of the kernel index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=2):\n",
    "        self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = tensor.random((out_channels, ))\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def __call__(self, X : tensor, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        X_col, act_h, act_w = Conv2d.im2col(X, kernel_size=self.kernel_size, stride=stride)\n",
    "        K_col_shape = (self.out_channels, self.kernel_size*self.kernel_size*self.in_channels)\n",
    "        K_col = self.kernel.reshape(K_col_shape).transpose()\n",
    "        Y_col = X_col @ K_col + self.bias\n",
    "        Y = Y_col.reshape((batch_size, self.out_channels, act_h, act_w))\n",
    "        pooled = Conv2d.maxpool2d(Y)\n",
    "        return pooled\n",
    "        \n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size=2, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_size)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_size)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            \n",
    "            grad_6D = out.grad.reshape(batch_size, act_h, act_w, channels, kernel_h, kernel_w)\n",
    "\n",
    "            for i in range(kernel_h):\n",
    "                for j in range(kernel_w):\n",
    "                    grad_slice = grad_6D[:, :, :, :, i, j]\n",
    "                    \n",
    "                    grad_slice_transposed = grad_slice.transpose(0, 3, 1, 2)\n",
    "                    \n",
    "                    X.grad[:, :, \n",
    "                        i : i + act_h * stride : stride, \n",
    "                        j : j + act_w * stride : stride\n",
    "                    ] += grad_slice_transposed\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out, act_h, act_w\n",
    "    \n",
    "    @classmethod\n",
    "    def maxpool2d(cls, Y: tensor, pool_size=2, stride=1):   \n",
    "        batch_number = Y.shape[0]\n",
    "        filters = Y.shape[1]\n",
    "        image_height = Y.shape[-2] #Rows\n",
    "        image_width = Y.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        pool_h = pool_size\n",
    "        pool_w = pool_size\n",
    "\n",
    "        pooled_h = (((image_height - pool_h)//stride) + 1) #height of activation\n",
    "        pooled_w = (((image_width - pool_w)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = Y.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            Y.matrix,\n",
    "                            shape=(batch_number, pooled_h, pooled_w, filters, pool_h, pool_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        intermediate_5D = np.reshape(intermediate_6D, (batch_number, filters, pooled_h, pooled_w, pool_h * pool_w))\n",
    "\n",
    "\n",
    "        out_matrix = np.max(intermediate_5D, axis = -1)\n",
    "        IndexA_for5D = np.argmax(intermediate_5D, axis = -1)\n",
    "\n",
    "        def _backward():\n",
    "            # Recover window position (i, j) from flat index in last dim\n",
    "            Y.grad = np.zeros_like(Y.matrix) if Y.grad is None else Y.grad\n",
    "            flat_idx = IndexA_for5D  # (B, F, pooled_h, pooled_w)\n",
    "            i = flat_idx // pool_w\n",
    "            j = flat_idx % pool_w\n",
    "\n",
    "            # Build grids for batch, filter, and pooled positions\n",
    "            b_grid = np.arange(batch_number).reshape(batch_number, 1, 1, 1)\n",
    "            f_grid = np.arange(filters).reshape(1, filters, 1, 1)\n",
    "            ph_grid = np.arange(pooled_h).reshape(1, 1, pooled_h, 1)\n",
    "            pw_grid = np.arange(pooled_w).reshape(1, 1, 1, pooled_w)\n",
    "\n",
    "            # Broadcast all to shape (B, F, pooled_h, pooled_w)\n",
    "            b_idx = np.broadcast_to(b_grid, flat_idx.shape)\n",
    "            f_idx = np.broadcast_to(f_grid, flat_idx.shape)\n",
    "            ph = np.broadcast_to(ph_grid, flat_idx.shape)\n",
    "            pw = np.broadcast_to(pw_grid, flat_idx.shape)\n",
    "\n",
    "            # Compute actual positions in Y where max values came from\n",
    "            h_idx = stride * ph + i\n",
    "            w_idx = stride * pw + j\n",
    "\n",
    "            # Accumulate gradients using 4D indexing\n",
    "            np.add.at(Y.grad, (b_idx.ravel(), f_idx.ravel(), h_idx.ravel(), w_idx.ravel()), out.grad.ravel())\n",
    "\n",
    "        out = tensor(out_matrix, _children=(Y, ), _operation=\"maxpool\")\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradient:\n",
      " [[ 0.          0.16558826  0.26603022  0.        ]\n",
      " [ 0.         -0.12948838 -0.21422252  0.13301511]\n",
      " [ 0.08279413  0.13301511 -0.06474419 -0.14850833]\n",
      " [-0.06474419 -0.14850833  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Test im2col gradient via Conv2d layer\n",
    "X = tensor(np.random.randn(1, 1, 4, 4))\n",
    "layer = Conv2d(in_channels=1, out_channels=1, kernel_size=2)\n",
    "Y = layer(X, stride=1)\n",
    "Y.backward()\n",
    "print(\"Input gradient:\\n\", X.grad[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da9de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/0mwc7nyn64x7k2f0jlg9hs300000gn/T/ipykernel_89464/2651310694.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 16 + 1) instead\n",
      "  numbers = np.random.random_integers(0,16, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = np.random.random_integers(0,16, 16)\n",
    "Y = numbers.reshape(16,1)\n",
    "act_h = 4\n",
    "act_w = 4\n",
    "istrides = Y.strides\n",
    "istrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01be75d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Conv2d.__call__() got an unexpected keyword argument 'stride'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m X = tensor(np.random.randn(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      3\u001b[39m layer = Conv2d(in_channels=\u001b[32m1\u001b[39m, out_channels=\u001b[32m1\u001b[39m, kernel_size=\u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m Y = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m Y.backward()\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInput gradient:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, X.grad[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: Conv2d.__call__() got an unexpected keyword argument 'stride'"
     ]
    }
   ],
   "source": [
    "# Test maxpool gradient via Conv2d layer\n",
    "X = tensor(np.random.randn(1, 1, 4, 4))\n",
    "layer = Conv2d(in_channels=1, out_channels=1, kernel_size=2)\n",
    "Y = layer(X, stride=1)\n",
    "Y.backward()\n",
    "print(\"Input gradient:\\n\", X.grad[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a6478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=2, stride=1, padding = -1):\n",
    "        #self.kernel = tensor.random((out_channels, in_channels, kernel_size, kernel_size))\n",
    "        fan_in = in_channels * kernel_size * kernel_size\n",
    "        self.kernel = tensor.he_init((out_channels, in_channels, kernel_size, kernel_size), fan_in)\n",
    "        self.bias = tensor.zeros((out_channels, ))\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.kernel, self.bias]\n",
    "\n",
    "    def __call__(self, X : tensor):\n",
    "\n",
    "        batch_size, channels, h, w = X.shape\n",
    "\n",
    "        if self.padding == -1: #same padding\n",
    "            pad_h = (self.stride *(h - 1) + self.kernel_size - h)//2\n",
    "            pad_w = (self.stride*(w - 1) + self.kernel_size - w)//2\n",
    "            X_padded = X.padding(pad_h, pad_w)\n",
    "\n",
    "        elif self.padding > 0:\n",
    "            X_padded = X.padding(self.padding, self.padding)\n",
    "\n",
    "        else:\n",
    "            X_padded = X\n",
    "\n",
    "        X_col, act_h, act_w = Conv2d.im2col(X_padded, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        K_col_shape = (self.out_channels, self.kernel_size*self.kernel_size*self.in_channels)\n",
    "        K_col = self.kernel.reshape(K_col_shape).transpose()\n",
    "        Y_col = X_col @ K_col + self.bias\n",
    "        Y = Y_col.reshape((batch_size, self.out_channels, act_h, act_w))\n",
    "        return Y\n",
    "        \n",
    "    @classmethod\n",
    "    def im2col(cls, X : tensor, kernel_size=2, stride=1):\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "        channels = X.shape[1]\n",
    "        image_height = X.shape[-2] #Rows\n",
    "        image_width = X.shape[-1] #Columns\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        kernel_h = kernel_size\n",
    "        kernel_w = kernel_size\n",
    "\n",
    "        act_h = (((image_height - kernel_h)//stride) + 1) #height of activation\n",
    "        act_w = (((image_width - kernel_w)//stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = X.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            X.matrix,\n",
    "                            shape=(batch_size, act_h, act_w, channels, kernel_h, kernel_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        out_shape = (batch_size * act_h * act_w, channels * kernel_h * kernel_w)\n",
    "        out_matrix = np.reshape(intermediate_6D, shape=out_shape)\n",
    "\n",
    "\n",
    "        def _backward():\n",
    "            X.grad = np.zeros_like(X.matrix) if X.grad is None else X.grad\n",
    "            \n",
    "            grad_6D = out.grad.reshape(batch_size, act_h, act_w, channels, kernel_h, kernel_w)\n",
    "            for i in range(kernel_h):\n",
    "                for j in range(kernel_w):\n",
    "                    grad_slice = grad_6D[:, :, :, :, i, j]\n",
    "                    \n",
    "                    grad_slice_transposed = grad_slice.transpose(0, 3, 1, 2)\n",
    "                    X.grad[:, :, \n",
    "                        i : i + act_h * stride : stride, \n",
    "                        j : j + act_w * stride : stride\n",
    "                    ] += grad_slice_transposed\n",
    "\n",
    "        out = tensor(out_matrix, _children=(X, ), _operation='im2col')\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out, act_h, act_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39002f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maxpool2D:\n",
    "    def __init__(self, in_channels, pool_size = 2, stride = 1):\n",
    "        self.in_channels = in_channels\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def __call__(self, Y: tensor):\n",
    "\n",
    "        batch_number = Y.shape[0]\n",
    "        filters = Y.shape[1]\n",
    "        image_height = Y.shape[-2] #Rows\n",
    "        image_width = Y.shape[-1] #Columns\n",
    "\n",
    "\n",
    "        #We are assuming square kernels.\n",
    "        pool_h = self.pool_size\n",
    "        pool_w = self.pool_size\n",
    "\n",
    "        pooled_h = (((image_height - pool_h)//self.stride) + 1) #height of activation\n",
    "        pooled_w = (((image_width - pool_w)//self.stride) + 1)  #width of activation\n",
    "\n",
    "        istrides = Y.matrix.strides #strides of input tensor\n",
    "\n",
    "        intermediate_6D = np.lib.stride_tricks.as_strided(\n",
    "                            Y.matrix,\n",
    "                            shape=(batch_number, pooled_h, pooled_w, filters, pool_h, pool_w),\n",
    "                            strides=(istrides[0], #No of images stride bytes\n",
    "                                     istrides[-2] * self.stride, #Activation map Vertical stride bytes\n",
    "                                     istrides[-1] * self.stride, #Activation map Horizontal stride bytes\n",
    "                                     istrides[1], #Channel stride bytes\n",
    "                                     istrides[-2], #Rective field vertical stride bytes\n",
    "                                     istrides[-1]) #Receptive field horizontal stride bytes\n",
    "                            )\n",
    "        \n",
    "        intermediate_6D_transposed = intermediate_6D.transpose(0, 3, 1, 2, 4, 5)\n",
    "        intermediate_5D = intermediate_6D_transposed.reshape(batch_number, filters, pooled_h, pooled_w, pool_h * pool_w)\n",
    "\n",
    "        out_matrix = np.max(intermediate_5D, axis=-1)\n",
    "        IndexA_for5D = np.argmax(intermediate_5D, axis=-1)\n",
    "\n",
    "        def _backward():\n",
    "            # Recover window position (i, j) from flat index in last dim\n",
    "            Y.grad = np.zeros_like(Y.matrix) if Y.grad is None else Y.grad\n",
    "            flat_idx = IndexA_for5D  # (B, F, pooled_h, pooled_w)\n",
    "            i = flat_idx // pool_w\n",
    "            j = flat_idx % pool_w\n",
    "\n",
    "            # Build grids for batch, filter, and pooled positions\n",
    "            b_grid = np.arange(batch_number).reshape(batch_number, 1, 1, 1)\n",
    "            f_grid = np.arange(filters).reshape(1, filters, 1, 1)\n",
    "            ph_grid = np.arange(pooled_h).reshape(1, 1, pooled_h, 1)\n",
    "            pw_grid = np.arange(pooled_w).reshape(1, 1, 1, pooled_w)\n",
    "\n",
    "            # Broadcast all to shape (B, F, pooled_h, pooled_w)\n",
    "            b_idx = np.broadcast_to(b_grid, flat_idx.shape)\n",
    "            f_idx = np.broadcast_to(f_grid, flat_idx.shape)\n",
    "            ph = np.broadcast_to(ph_grid, flat_idx.shape)\n",
    "            pw = np.broadcast_to(pw_grid, flat_idx.shape)\n",
    "\n",
    "            # Compute actual positions in Y where max values came from\n",
    "            h_idx = self.stride * ph + i\n",
    "            w_idx = self.stride * pw + j\n",
    "\n",
    "            # Accumulate gradients using 4D indexing\n",
    "            np.add.at(Y.grad, (b_idx.ravel(), f_idx.ravel(), h_idx.ravel(), w_idx.ravel()), out.grad.ravel())\n",
    "\n",
    "        out = tensor(out_matrix, _children=(Y, ), _operation=\"maxpool\")\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cc1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \n",
    "        self.bias = tensor.zeros((out_features, 1))\n",
    "        self.weights = tensor.he_init((out_features, in_features), in_features)\n",
    "        #self.weights = tensor.random((out_features, in_features))\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.bias]\n",
    "\n",
    "    def __call__(self, X:tensor):\n",
    "        return (self.weights @ X) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20424c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, in_channels, layers, kernels_in_layers, kernels_shape, conv_strides, pool_shape, pool_strides, FCL_weights):\n",
    "\n",
    "        self.in_channels = (in_channels, ) + kernels_in_layers\n",
    "        self.FCL_weights = FCL_weights\n",
    "        self.layers = layers\n",
    "        #self.conv_layers = [Conv2d(in_channels[layer], kernels_in_layers[layer], kernels_shape[layer], conv_strides[layer]) for layer in range(layers)]\n",
    "        self.conv_layers = [Conv2d(self.in_channels[layer], kernels_in_layers[layer], kernels_shape[layer], conv_strides[layer]) for layer in range(layers)]\n",
    "        self.pool_layers = [maxpool2D(kernels_in_layers[layer], pool_shape[layer], pool_strides[layer]) for layer in range(layers)]\n",
    "        self.FC_layers = [None for _ in range(layers+1)]\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in range(self.layers):\n",
    "            params.extend(self.conv_layers[layer].parameters())\n",
    "            params.extend(self.FC_layers[layer].parameters())\n",
    "        params.extend(self.FC_layers[layer+1].parameters())\n",
    "        return params\n",
    "\n",
    "    def __call__(self, X:tensor):\n",
    "        b = X\n",
    "        for layer in range(self.layers):\n",
    "            a_ = self.conv_layers[layer](b)\n",
    "            a = a_.ReLU()\n",
    "            b = self.pool_layers[layer](a)\n",
    "        \n",
    "        c:tensor = b.reshape((X.shape[0], -1)).transpose()\n",
    "        if self.FC_layers[0] is None:\n",
    "            self.FC_layers[0] = FC(c.shape[0], self.FCL_weights[0])\n",
    "\n",
    "        for layer in range(self.layers+1):\n",
    "            if self.FC_layers[layer] is None:\n",
    "                self.FC_layers[layer] = FC(self.FCL_weights[layer-1], self.FCL_weights[layer])\n",
    "\n",
    "            c = self.FC_layers[layer](c)\n",
    "            \n",
    "            if layer < self.layers:\n",
    "                c = c.ReLU()\n",
    "        \n",
    "        out = c.transpose()\n",
    "        return out\n",
    "    \n",
    "    @classmethod\n",
    "    def cross_entropy_loss(cls, ypredicted: tensor, ytrue, batch_size):\n",
    "        ytrue =  tensor(ytrue) if not isinstance(ytrue, tensor) else ytrue\n",
    "        cross_entropy = -1*ypredicted.log_softmax(axis=-1)\n",
    "        loss = ((ytrue * cross_entropy).sum())/batch_size\n",
    "        #loss = ((ytrue * cross_entropy).sum())\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 10, lr = 0.001, batch_size = 32):\n",
    "        lossT = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            n_batches = 0\n",
    "            perm = np.random.permutation(len(X_train))\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                idx = perm[i:i+batch_size]\n",
    "                xb = tensor(X_train[idx])             \n",
    "                yb = tensor(y_train[idx]) \n",
    "\n",
    "                y_predicted = self(xb)\n",
    "                ce_loss = CNN.cross_entropy_loss(y_predicted, yb, len(idx))\n",
    "                ce_loss.backward()\n",
    "\n",
    "                for param in self.parameters():\n",
    "                    if param.grad is not None:\n",
    "\n",
    "                        #grad_clipped = np.clip(param.grad, -1.0, 1.0)\n",
    "                        #param.matrix -= lr * grad_clipped\n",
    "                        param.matrix -= lr * param.grad\n",
    "                        param.grad = None\n",
    "\n",
    "                epoch_loss += ce_loss.matrix.flatten()[0]\n",
    "                n_batches += 1\n",
    "                # Clean up\n",
    "                ce_loss.cleanBackward()\n",
    "                del xb, yb, y_predicted, ce_loss\n",
    "            \n",
    "            avg_loss = epoch_loss / n_batches    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
    "            lossT.append((epoch, avg_loss))\n",
    "\n",
    "        return lossT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba188a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m X = tensor.random((\u001b[32m4\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m32\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m c = \u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m out = c(X)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(out.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mCNN.__init__\u001b[39m\u001b[34m(self, in_channels, layers, kernels_in_layers, kernels_shape, conv_strides, pool_shape, pool_strides, FCL_weights)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mself\u001b[39m.layers = layers\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#self.conv_layers = [Conv2d(in_channels[layer], kernels_in_layers[layer], kernels_shape[layer], conv_strides[layer]) for layer in range(layers)]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mself\u001b[39m.conv_layers = [\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernels_in_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernels_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_strides\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layers)]\n\u001b[32m      9\u001b[39m \u001b[38;5;28mself\u001b[39m.pool_layers = [maxpool2D(kernels_in_layers[layer], pool_shape[layer], pool_strides[layer]) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layers)]\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.FC_layers = [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layers+\u001b[32m1\u001b[39m)]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mConv2d.__init__\u001b[39m\u001b[34m(self, in_channels, out_channels, kernel_size, stride)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels=\u001b[32m1\u001b[39m, out_channels=\u001b[32m1\u001b[39m, kernel_size=\u001b[32m2\u001b[39m, stride=\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mself\u001b[39m.kernel = \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m#fan_in = in_channels * kernel_size * kernel_size\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m#self.kernel = tensor.he_init((out_channels, in_channels, kernel_size, kernel_size), fan_in)\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias = tensor.zeros((out_channels, ))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtensor.random\u001b[39m\u001b[34m(cls, shape, dtype)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrandom\u001b[39m(\u001b[38;5;28mcls\u001b[39m, shape, dtype = np.float32):\n\u001b[32m     27\u001b[39m     t = tensor()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     t.matrix = (\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m * \u001b[32m0.1\u001b[39m).astype(dtype=dtype)\n\u001b[32m     29\u001b[39m     t.shape = shape\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:1310\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.randn\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:1470\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.standard_normal\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/_common.pyx:654\u001b[39m, in \u001b[36mnumpy.random._common.cont\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "X = tensor.random((4, 3, 32, 32))\n",
    "c = CNN((3,5, ), 2, (5, 16, ), (5, 5, ), (1, 1, ), (2, 2, ), (1, 1, ), (128, 64, 10, ))\n",
    "out = c(X)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9119f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawanadhikari/Documents/Roadmap/MachineLearningMaths/.venv/lib/python3.14/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:, np.newaxis, :, :].astype(np.float32) / 255.0  \n",
    "X_test = X_test[:, np.newaxis, :, :].astype(np.float32) / 255.0\n",
    "Y_train = np.zeros((y_train.size, 10))\n",
    "Y_train[np.arange(y_train.size), y_train] = 1\n",
    "Y_test = np.zeros((y_test.size, 10))\n",
    "Y_test[np.arange(y_test.size), y_test] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0afa543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 58.976871\n",
      "Epoch 2/50, Loss: 26.314802\n",
      "Epoch 3/50, Loss: 14.733776\n",
      "Epoch 4/50, Loss: 11.595317\n",
      "Epoch 5/50, Loss: 6.554394\n",
      "Epoch 6/50, Loss: 5.070572\n",
      "Epoch 7/50, Loss: 6.244931\n",
      "Epoch 8/50, Loss: 2.135672\n",
      "Epoch 9/50, Loss: 1.348820\n",
      "Epoch 10/50, Loss: 1.081510\n",
      "Epoch 11/50, Loss: 0.161435\n",
      "Epoch 12/50, Loss: 0.062407\n",
      "Epoch 13/50, Loss: 0.020051\n",
      "Epoch 14/50, Loss: 0.012070\n",
      "Epoch 15/50, Loss: 0.009297\n",
      "Epoch 16/50, Loss: 0.007568\n",
      "Epoch 17/50, Loss: 0.006398\n",
      "Epoch 18/50, Loss: 0.005535\n",
      "Epoch 19/50, Loss: 0.004881\n",
      "Epoch 20/50, Loss: 0.004381\n",
      "Epoch 21/50, Loss: 0.003961\n",
      "Epoch 22/50, Loss: 0.003619\n",
      "Epoch 23/50, Loss: 0.003331\n",
      "Epoch 24/50, Loss: 0.003077\n",
      "Epoch 25/50, Loss: 0.002866\n",
      "Epoch 26/50, Loss: 0.002676\n",
      "Epoch 27/50, Loss: 0.002512\n",
      "Epoch 28/50, Loss: 0.002366\n",
      "Epoch 29/50, Loss: 0.002238\n",
      "Epoch 30/50, Loss: 0.002120\n",
      "Epoch 31/50, Loss: 0.002018\n",
      "Epoch 32/50, Loss: 0.001920\n",
      "Epoch 33/50, Loss: 0.001835\n",
      "Epoch 34/50, Loss: 0.001754\n",
      "Epoch 35/50, Loss: 0.001686\n",
      "Epoch 36/50, Loss: 0.001619\n",
      "Epoch 37/50, Loss: 0.001555\n",
      "Epoch 38/50, Loss: 0.001500\n",
      "Epoch 39/50, Loss: 0.001445\n",
      "Epoch 40/50, Loss: 0.001396\n",
      "Epoch 41/50, Loss: 0.001350\n",
      "Epoch 42/50, Loss: 0.001306\n",
      "Epoch 43/50, Loss: 0.001263\n",
      "Epoch 44/50, Loss: 0.001227\n",
      "Epoch 45/50, Loss: 0.001190\n",
      "Epoch 46/50, Loss: 0.001156\n",
      "Epoch 47/50, Loss: 0.001123\n",
      "Epoch 48/50, Loss: 0.001092\n",
      "Epoch 49/50, Loss: 0.001063\n",
      "Epoch 50/50, Loss: 0.001037\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CNN(\n",
    "    in_channels=1,\n",
    "    layers=2,\n",
    "    kernels_in_layers= (5, 16, ),\n",
    "    kernels_shape= (5, 5, ),\n",
    "    conv_strides= (1, 1, ),\n",
    "    pool_shape= (2, 2, ),\n",
    "    pool_strides= (2, 2, ), \n",
    "    FCL_weights= (64, 32, 10) #4 Fully Connected Layers including one output layer. \n",
    ")\n",
    "\n",
    "#We will be training on 1/10th of the total dataset.\n",
    "loss = model.fit(X_train[:1000], Y_train[:1000], epochs=50, lr=0.01, batch_size=32)\n",
    "\n",
    "#Plot Train Loss vs Epochs graph.\n",
    "epochs, losses = zip(*loss)\n",
    "plt.plot(epochs, losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1a1c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities (first 5 samples):\n",
      "[[2.7668572e-09 9.9980670e-01 1.6304980e-04 4.2345068e-08 5.2662466e-07\n",
      "  1.0371447e-06 2.0942307e-05 1.5751374e-06 6.0203784e-06 1.2330777e-07]\n",
      " [2.2753070e-11 9.9621686e-11 1.1131790e-08 1.6041957e-10 4.6322245e-11\n",
      "  1.9038033e-12 2.5178761e-12 9.9999988e-01 3.6897693e-11 1.2814985e-07]\n",
      " [7.0524157e-24 6.9462352e-19 2.1095933e-17 4.8516390e-14 1.0000000e+00\n",
      "  9.2922459e-17 2.0110499e-17 1.2260512e-18 9.2974239e-12 1.2950668e-09]\n",
      " [2.5125029e-08 1.2295665e-08 9.9977183e-01 2.5106223e-10 1.9278545e-10\n",
      "  1.1904547e-09 2.2748167e-04 9.2306973e-10 6.6858155e-07 1.5468418e-11]\n",
      " [4.4661985e-09 5.7419370e-06 2.7992475e-11 1.6779626e-05 1.7352196e-10\n",
      "  9.9997735e-01 5.4053040e-10 1.4157932e-13 1.4794688e-07 1.2011637e-11]]\n",
      "Actual labels (first 5 samples):\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Predicted classes: [1 7 4 2 5]\n",
      "True classes: [1 7 4 2 3]\n",
      "Accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "xtest = X_test[40:45]\n",
    "ytest = Y_test[40:45]\n",
    "\n",
    "for image in xtest:\n",
    "    for channel in image:\n",
    "        plt.imshow(channel, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "ypred = model(tensor(xtest))\n",
    "probs = ypred.softmax()\n",
    "\n",
    "print(\"Predicted probabilities (first 5 samples):\")\n",
    "print(probs.matrix)\n",
    "print(\"Actual labels (first 5 samples):\")\n",
    "print(ytest)\n",
    "\n",
    "# Check argmax accuracy\n",
    "pred_classes = np.argmax(probs.matrix, axis=1)\n",
    "true_classes = np.argmax(ytest, axis=1)\n",
    "print(f\"Predicted classes: {pred_classes}\")\n",
    "print(f\"True classes: {true_classes}\")\n",
    "print(f\"Accuracy: {(pred_classes == true_classes).mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ae0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = X_test[:10]\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5cb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "for image in xtest:\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39508fe5",
   "metadata": {},
   "source": [
    "Need Same Padding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd0e96",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
