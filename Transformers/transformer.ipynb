{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df96525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b8ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloc = Path(\"./Data/input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534e8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (dataloc, 'r', encoding='utf-8') as datafile:\n",
    "    data = datafile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64ab40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06033338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 65\n",
      "Vocabulary: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(data))\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n",
    "print(f\"Vocabulary: {vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155a30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tokenizer:\n",
    "    def __init__(self, mode = 'char', max_vocab_size=None):\n",
    "        self.mode = mode\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "\n",
    "        self.vocab = set()\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def train(self, dataset):\n",
    "        if self.mode == 'char':\n",
    "            self.vocab = sorted(set(dataset))\n",
    "            self.stoi = {c:i for i, c in enumerate(self.vocab)}\n",
    "            self.itos = {i:c for i, c in enumerate(self.vocab)}\n",
    "        elif self.mode == 'word':\n",
    "            self.vocab = sorted(set(dataset.split()))\n",
    "            self.stoi = {s:i for i, s in enumerate(self.vocab)}\n",
    "            self.itos = {i:s for i, s in enumerate(self.vocab)}\n",
    "        else:\n",
    "            print(f\"{self.mode} not supported yet! We only support 'char' and 'word'!\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        if len(self.stoi) == 0:\n",
    "            raise ValueError(\"First run train method on your data!\")\n",
    "        \n",
    "        if self.mode == 'char':\n",
    "            return [self.stoi[c] for c in text]\n",
    "        elif self.mode == 'word':\n",
    "            return [self.stoi[c] for c in text.split()]\n",
    "        else:\n",
    "            raise ValueError(f\"{self.mode} not supported yet! We only support 'char' and 'word'!\")\n",
    "\n",
    "    def decode(self, ints):\n",
    "        if len(self.itos) == 0:\n",
    "            raise ValueError(\"First run train method on your data!\")\n",
    "        \n",
    "        tlists = [self.itos[i] for i in ints]\n",
    "        if self.mode == 'char':\n",
    "            return \"\".join(tlists)\n",
    "        elif self.mode == 'word':\n",
    "            return \" \".join(tlists)\n",
    "        else: \n",
    "            raise ValueError(f\"{self.mode} not supported yet! We only support 'char' and 'word'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c965cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42, 2, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer('char')\n",
    "t.train(data)\n",
    "encoded = t.encode(\"Hello World!!\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db341f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = t.decode(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aed0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
